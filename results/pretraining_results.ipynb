{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from traindata import Traindata\n",
    "from utilities import *\n",
    "\n",
    "PATH = \"pretraining_results_1/\"\n",
    "reps = getreps(PATH=\"../data/phonreps.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from CSV per model, not per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "fry = {}\n",
    "ewfg = {}\n",
    "\n",
    "with open('pretraining_results_1.csv', 'w') as f:\n",
    "\n",
    "    f.write(\"model_id, epoch, condition, phonemewise_accuracy, wordwise_accuracy\\n\")\n",
    "    for filename in os.listdir(PATH):\n",
    "        if filename.endswith(\".pkl\"):\n",
    "            filepath = os.path.join(PATH, filename)\n",
    "\n",
    "        epoch = re.search(r'epoch_(.*?)\\.pkl', filename).group(1)\n",
    "        model_id = re.search(r'pretraining_(.*?)\\_epoch', filename).group(1)\n",
    "\n",
    "        with open(filepath, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "\n",
    "        # train\n",
    "        f.write(\"{model_id}, {epoch}, {condition}, {phonemewise_accuracy}, {wordwise_accuracy}\\n\".format(\n",
    "            model_id = model_id,\n",
    "            epoch = epoch,\n",
    "            condition = 'train',\n",
    "            phonemewise_accuracy = data['pretraining']['phoneme_wise_accuracy'],\n",
    "            wordwise_accuracy = data['pretraining']['word_wise_accuracy']\n",
    "        )\n",
    "        )\n",
    "\n",
    "        # ewfg\n",
    "        f.write(\"{model_id}, {epoch}, {condition}, {phonemewise_accuracy}, {wordwise_accuracy}\\n\".format(\n",
    "            model_id = model_id,\n",
    "            epoch = epoch,\n",
    "            condition = 'ewfg',\n",
    "            phonemewise_accuracy = data['ewfg']['phoneme_wise_accuracy'],\n",
    "            wordwise_accuracy = data['ewfg']['word_wise_accuracy']\n",
    "        )\n",
    "        )\n",
    "\n",
    "        # fry\n",
    "        f.write(\"{model_id}, {epoch}, {set}, {phonemewise_accuracy}, {wordwise_accuracy}\\n\".format(\n",
    "            model_id = model_id,\n",
    "            epoch = epoch,\n",
    "            set = 'fry',\n",
    "            phonemewise_accuracy = data['fry_1980']['phoneme_wise_accuracy'],\n",
    "            wordwise_accuracy = data['fry_1980']['word_wise_accuracy']\n",
    "        )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data from PKL, including data for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'pretraining_results_1'\n",
    "\n",
    "# find all the PKL files\n",
    "checkpoints = [file for file in os.listdir(PATH) if file.endswith('.pkl')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First clone the tensors to avoid modifying the originals\n",
    "phon_preds = data[\"pretraining\"][\"phon_predictions\"].clone()\n",
    "phon_targets = data[\"pretraining\"][\"phon_targets\"].clone()\n",
    "\n",
    "# ===== FEATURE LEVEL ACCURACY =====\n",
    "# Create mask for valid features (valid means not padding tokens which are marked as 2)  \n",
    "phon_features_mask = phon_targets != 2\n",
    "\n",
    "# Find which predictions match targets, but only count valid features\n",
    "masked_equalities = torch.eq(phon_preds, phon_targets) & phon_features_mask\n",
    "\n",
    "# Calculate overall feature accuracy across entire dataset\n",
    "feature_accuracy = masked_equalities.sum() / phon_features_mask.sum()\n",
    "print(\"\\nOverall Feature-Level Accuracy:\", feature_accuracy.item())\n",
    "\n",
    "# ===== PHONEME LEVEL ACCURACY =====\n",
    "# A phoneme is correct only if ALL its features are correct\n",
    "# We use .all(dim=2) to check across feature dimension\n",
    "phoneme_correct = masked_equalities.all(dim=2)\n",
    "\n",
    "# Identify valid phonemes (those where not all features are 2/padding)\n",
    "valid_phonemes = ~(phon_targets == 2).all(dim=2)\n",
    "\n",
    "# Calculate overall phoneme accuracy\n",
    "phoneme_accuracy = phoneme_correct[valid_phonemes].sum() / valid_phonemes.sum()\n",
    "print(\"Overall Phoneme-Level Accuracy:\", phoneme_accuracy.item())\n",
    "\n",
    "# ===== WORD LEVEL ACCURACY =====\n",
    "# A word is correct only if ALL its valid phonemes are correct\n",
    "word_correct = torch.all(phoneme_correct | ~valid_phonemes, dim=1)\n",
    "word_accuracy = word_correct.sum() / float(word_correct.size(0))\n",
    "print(\"Overall Word-Level Accuracy:\", word_accuracy.item())\n",
    "\n",
    "# ===== PER-WORD DETAILED ANALYSIS =====\n",
    "print(\"\\nDetailed per-word analysis:\")\n",
    "for i in range(5):  # Show first 5 words as example\n",
    "   # Count valid features for this word\n",
    "   n_valid_features = phon_features_mask[i].sum().item()\n",
    "   n_correct_features = masked_equalities[i].sum().item()\n",
    "   \n",
    "   # Count valid phonemes for this word\n",
    "   n_valid_phonemes = valid_phonemes[i].sum().item()\n",
    "   n_correct_phonemes = (phoneme_correct[i] & valid_phonemes[i]).sum().item()\n",
    "   \n",
    "   print(f\"\\nWord {i}:\")\n",
    "   print(f\"Features: {n_correct_features}/{n_valid_features} correct\")\n",
    "   print(f\"Phonemes: {n_correct_phonemes}/{n_valid_phonemes} correct\")\n",
    "   print(f\"Word-level: {'Correct' if word_correct[i] else 'Incorrect'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'pretraining'\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "\n",
    "    data = pickle.load(open(PATH + \"/\" + checkpoint, \"rb\"))\n",
    "    epoch = re.search(r'epoch_(.*?)\\.pkl', checkpoint).group(1)\n",
    "    model_id = re.search(r'pretraining_(.*?)\\_epoch', checkpoint).group(1)\n",
    "\n",
    "\n",
    "    # First clone the tensors to avoid modifying the originals\n",
    "    phon_preds = data[\"pretraining\"][\"phon_predictions\"].clone()\n",
    "    phon_targets = data[\"pretraining\"][\"phon_targets\"].clone()\n",
    "\n",
    "    # ===== FEATURE LEVEL ACCURACY =====\n",
    "    # Create mask for valid features (valid means not padding tokens which are marked as 2)  \n",
    "    phon_features_mask = phon_targets != 2\n",
    "\n",
    "    # Find which predictions match targets, but only count valid features\n",
    "    masked_equalities = torch.eq(phon_preds, phon_targets) & phon_features_mask\n",
    "\n",
    "    # Calculate overall feature accuracy across entire dataset\n",
    "    feature_accuracy = masked_equalities.sum() / phon_features_mask.sum()\n",
    "\n",
    "    # ===== PHONEME LEVEL ACCURACY =====\n",
    "    # A phoneme is correct only if ALL its features are correct\n",
    "    # We use .all(dim=2) to check across feature dimension\n",
    "    phoneme_correct = masked_equalities.all(dim=2)\n",
    "\n",
    "    # Identify valid phonemes (those where not all features are 2/padding)\n",
    "    valid_phonemes = ~(phon_targets == 2).all(dim=2)\n",
    "\n",
    "    # Calculate overall phoneme accuracy\n",
    "    phoneme_accuracy = phoneme_correct[valid_phonemes].sum() / valid_phonemes.sum()\n",
    "\n",
    "    # ===== WORD LEVEL ACCURACY =====\n",
    "    # A word is correct only if ALL its valid phonemes are correct\n",
    "    word_correct = torch.all(phoneme_correct | ~valid_phonemes, dim=1)\n",
    "    word_accuracy = word_correct.sum() / float(word_correct.size(0))\n",
    "\n",
    "    with open('pretraining_results_1/CSV/pretrain_words_results_' + model_id + '_' + 'epoch' + '_' + epoch + '.csv', 'w') as f:\n",
    "\n",
    "        f.write(\"model_id, epoch, training_phase, condition, word, featurewise_accuracy, phonemewise_accuracy, wordwise_accuracy\\n\")\n",
    "\n",
    "        for i in range(len(data[DATASET]['words'])):\n",
    "\n",
    "            n_valid_features = phon_features_mask[i].sum().item()\n",
    "            n_correct_features = masked_equalities[i].sum().item()\n",
    "            \n",
    "            # Count valid phonemes for this word\n",
    "            n_valid_phonemes = valid_phonemes[i].sum().item()\n",
    "            n_correct_phonemes = (phoneme_correct[i] & valid_phonemes[i]).sum().item()\n",
    "\n",
    "            word = data[DATASET]['words'][i]        \n",
    "\n",
    "            f.write(\"{model_id}, {epoch}, {training_phase}, {condition}, {word}, {featurewise_accuracy}, {phonemewise_accuracy}, {wordwise_accuracy}\\n\".format(\n",
    "                model_id = model_id,\n",
    "                epoch = epoch,\n",
    "                training_phase = 'pretrain',\n",
    "                condition = 'pretrain',\n",
    "                word = word,\n",
    "                featurewise_accuracy = n_correct_features/n_valid_features,\n",
    "                phonemewise_accuracy = n_correct_phonemes/n_valid_phonemes,\n",
    "                wordwise_accuracy = word_correct[i]\n",
    "            )\n",
    "        )\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fry Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'fry_1980'\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "\n",
    "    data = pickle.load(open(PATH + \"/\" + checkpoint, \"rb\"))\n",
    "    epoch = re.search(r'epoch_(.*?)\\.pkl', checkpoint).group(1)\n",
    "    model_id = re.search(r'pretraining_(.*?)\\_epoch', checkpoint).group(1)\n",
    "\n",
    "    phon_preds = data[DATASET][\"phon_predictions\"].clone()\n",
    "    phon_targets = data[DATASET][\"phon_targets\"].clone()\n",
    "\n",
    "    phon_features_mask = phon_targets != 2\n",
    "\n",
    "    masked_equalities = torch.eq(phon_preds, phon_targets) & phon_features_mask\n",
    "\n",
    "    feature_accuracy = masked_equalities.sum() / phon_features_mask.sum()\n",
    "\n",
    "    phoneme_correct = masked_equalities.all(dim=2)\n",
    "\n",
    "    valid_phonemes = ~(phon_targets == 2).all(dim=2)\n",
    "\n",
    "    phoneme_accuracy = phoneme_correct[valid_phonemes].sum() / valid_phonemes.sum()\n",
    "\n",
    "    word_correct = torch.all(phoneme_correct | ~valid_phonemes, dim=1)\n",
    "    word_accuracy = word_correct.sum() / float(word_correct.size(0))\n",
    "\n",
    "    with open('pretraining_results_1/CSV/fry_words_results_' + model_id + '_' + 'epoch' + '_' + epoch + '.csv', 'w') as f:\n",
    "\n",
    "        f.write(\"model_id, epoch, training_phase, condition, word, featurewise_accuracy, phonemewise_accuracy, wordwise_accuracy\\n\")\n",
    "\n",
    "        for i in range(len(data[DATASET]['words'])):\n",
    "\n",
    "            n_valid_features = phon_features_mask[i].sum().item()\n",
    "            n_correct_features = masked_equalities[i].sum().item()\n",
    "            \n",
    "            # Count valid phonemes for this word\n",
    "            n_valid_phonemes = valid_phonemes[i].sum().item()\n",
    "            n_correct_phonemes = (phoneme_correct[i] & valid_phonemes[i]).sum().item()\n",
    "        \n",
    "            word = data[DATASET]['words'][i]\n",
    "\n",
    "            f.write(\"{model_id}, {epoch}, {training_phase}, {condition}, {word}, {featurewise_accuracy}, {phonemewise_accuracy}, {wordwise_accuracy}\\n\".format(\n",
    "                model_id = model_id,\n",
    "                epoch = epoch,\n",
    "                training_phase = 'pretrain',\n",
    "                condition = 'fry_1980',\n",
    "                word = word,\n",
    "                featurewise_accuracy = n_correct_features/n_valid_features,\n",
    "                phonemewise_accuracy = n_correct_phonemes/n_valid_phonemes,\n",
    "                wordwise_accuracy = word_correct[i]\n",
    "            )\n",
    "        )\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWFG Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ewfg'\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "\n",
    "    data = pickle.load(open(PATH + \"/\" + checkpoint, \"rb\"))\n",
    "    epoch = re.search(r'epoch_(.*?)\\.pkl', checkpoint).group(1)\n",
    "    model_id = re.search(r'pretraining_(.*?)\\_epoch', checkpoint).group(1)\n",
    "\n",
    "    phon_preds = data[DATASET][\"phon_predictions\"].clone()\n",
    "    phon_targets = data[DATASET][\"phon_targets\"].clone()\n",
    "\n",
    "    phon_features_mask = phon_targets != 2\n",
    "\n",
    "    masked_equalities = torch.eq(phon_preds, phon_targets) & phon_features_mask\n",
    "\n",
    "    feature_accuracy = masked_equalities.sum() / phon_features_mask.sum()\n",
    "\n",
    "    phoneme_correct = masked_equalities.all(dim=2)\n",
    "\n",
    "    valid_phonemes = ~(phon_targets == 2).all(dim=2)\n",
    "\n",
    "    phoneme_accuracy = phoneme_correct[valid_phonemes].sum() / valid_phonemes.sum()\n",
    "\n",
    "    word_correct = torch.all(phoneme_correct | ~valid_phonemes, dim=1)\n",
    "    word_accuracy = word_correct.sum() / float(word_correct.size(0))\n",
    "\n",
    "    with open('pretraining_results_1/CSV/ewfg_words_results_' + model_id + '_' + 'epoch' + '_' + epoch + '.csv', 'w') as f:\n",
    "\n",
    "        f.write(\"model_id, epoch, training_phase, condition, word, featurewise_accuracy, phonemewise_accuracy, wordwise_accuracy\\n\")\n",
    "\n",
    "        for i in range(len(data[DATASET]['words'])):\n",
    "\n",
    "            n_valid_features = phon_features_mask[i].sum().item()\n",
    "            n_correct_features = masked_equalities[i].sum().item()\n",
    "            \n",
    "            # Count valid phonemes for this word\n",
    "            n_valid_phonemes = valid_phonemes[i].sum().item()\n",
    "            n_correct_phonemes = (phoneme_correct[i] & valid_phonemes[i]).sum().item()\n",
    "        \n",
    "            word = data[DATASET]['words'][i]\n",
    "\n",
    "            f.write(\"{model_id}, {epoch}, {training_phase}, {condition}, {word}, {featurewise_accuracy}, {phonemewise_accuracy}, {wordwise_accuracy}\\n\".format(\n",
    "                model_id = model_id,\n",
    "                epoch = epoch,\n",
    "                training_phase = 'pretrain',\n",
    "                condition = 'ewfg',\n",
    "                word = word,\n",
    "                featurewise_accuracy = n_correct_features/n_valid_features,\n",
    "                phonemewise_accuracy = n_correct_phonemes/n_valid_phonemes,\n",
    "                wordwise_accuracy = word_correct[i]\n",
    "            )\n",
    "        )\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String form results\n",
    "This portion of the script generates the string form of the results, rather than their quantitative form. The code is separated from the quatitative results in order to reduce file size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining Words\n",
    "Data for the words from the pretraining routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'abra' in tmp[DATASET]['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aaron',\n",
       " 'abandoned',\n",
       " 'abbie',\n",
       " 'abby',\n",
       " 'abe',\n",
       " 'abed',\n",
       " 'abee',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abracadabra',\n",
       " 'absence',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'abstract',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accessorize',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accordion',\n",
       " 'ache',\n",
       " 'ack',\n",
       " 'acorn',\n",
       " 'acorns',\n",
       " 'acre',\n",
       " 'acrobat',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'activated',\n",
       " 'activity',\n",
       " 'acts',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'add',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'adjust',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admiring',\n",
       " 'adoption',\n",
       " 'adorable',\n",
       " 'adrian',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'advice',\n",
       " 'affect',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aggravated',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agricultural',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'aimee',\n",
       " 'aiming',\n",
       " 'air',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'ais',\n",
       " 'aislinn',\n",
       " 'ajax',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alaska',\n",
       " 'albert',\n",
       " 'album',\n",
       " 'albuquerque',\n",
       " 'ale',\n",
       " 'alec',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alf',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'aliens',\n",
       " 'alike',\n",
       " 'alissa',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allegiance',\n",
       " 'allen',\n",
       " 'allergic',\n",
       " 'alley',\n",
       " 'alleyway',\n",
       " 'alligator',\n",
       " 'allison',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'almond',\n",
       " 'almonds',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alphabet',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amanda',\n",
       " 'amara',\n",
       " 'amateurs',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amber',\n",
       " 'ambidextrous',\n",
       " 'ambulance',\n",
       " 'amelia',\n",
       " 'amen',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amigos',\n",
       " 'amount',\n",
       " 'amusement',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'analysis',\n",
       " 'ancestors',\n",
       " 'anchor',\n",
       " 'and',\n",
       " 'andrea',\n",
       " 'andreas',\n",
       " 'andrew',\n",
       " 'andy',\n",
       " 'anemone',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angelo',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angie',\n",
       " 'angle',\n",
       " 'angler',\n",
       " 'angles',\n",
       " 'angry',\n",
       " 'angus',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'anne',\n",
       " 'annie',\n",
       " 'announced',\n",
       " 'annoy',\n",
       " 'annoying',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'anteater',\n",
       " 'anthony',\n",
       " 'ants',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apartments',\n",
       " 'apes',\n",
       " 'apparently',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'apples',\n",
       " 'applesauce',\n",
       " 'applied',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciation',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'aqua',\n",
       " 'aquarium',\n",
       " 'ar',\n",
       " 'archaeologist',\n",
       " 'are',\n",
       " 'area',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'ariel',\n",
       " 'arizona',\n",
       " 'ark',\n",
       " 'arkansas',\n",
       " 'arm',\n",
       " 'armadillo',\n",
       " 'armadillos',\n",
       " 'armoire',\n",
       " 'armor',\n",
       " 'arms',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arranged',\n",
       " 'arrest',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrow',\n",
       " 'arrows',\n",
       " 'arsenio',\n",
       " 'art',\n",
       " 'arthur',\n",
       " 'arthurs',\n",
       " 'article',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'as',\n",
       " 'ascent',\n",
       " 'ashes',\n",
       " 'ashtray',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'asparagus',\n",
       " 'asphalt',\n",
       " 'asteroids',\n",
       " 'asthma',\n",
       " 'astonished',\n",
       " 'astra',\n",
       " 'astronaut',\n",
       " 'astronauts',\n",
       " 'astronomical',\n",
       " 'at',\n",
       " 'ate',\n",
       " 'atmosphere',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attachments',\n",
       " 'attack',\n",
       " 'attention',\n",
       " 'attic',\n",
       " 'attitude',\n",
       " 'audio',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'auntie',\n",
       " 'aunts',\n",
       " 'aurora',\n",
       " 'auto',\n",
       " 'avalanche',\n",
       " 'avenue',\n",
       " 'avocado',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'await',\n",
       " 'awake',\n",
       " 'awakened',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awhile',\n",
       " 'awoke',\n",
       " 'axe',\n",
       " 'axes',\n",
       " 'azaleas',\n",
       " 'b',\n",
       " 'baba',\n",
       " 'babar',\n",
       " 'babble',\n",
       " 'babe',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'babysit',\n",
       " 'babysitter',\n",
       " 'babysitting',\n",
       " 'back',\n",
       " 'backhoe',\n",
       " 'backpack',\n",
       " 'backs',\n",
       " 'backwards',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badge',\n",
       " 'badger',\n",
       " 'badly',\n",
       " 'bady',\n",
       " 'bag',\n",
       " 'bagel',\n",
       " 'baggage',\n",
       " 'baggy',\n",
       " 'bags',\n",
       " 'bagwell',\n",
       " 'bah',\n",
       " 'bailey',\n",
       " 'bait',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'baked',\n",
       " 'baker',\n",
       " 'bakery',\n",
       " 'baking',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balancing',\n",
       " 'balcony',\n",
       " 'bald',\n",
       " 'baldwin',\n",
       " 'bale',\n",
       " 'ball',\n",
       " 'ballerina',\n",
       " 'ballet',\n",
       " 'ballon',\n",
       " 'balloon',\n",
       " 'balloons',\n",
       " 'balls',\n",
       " 'baloney',\n",
       " 'baltimore',\n",
       " 'bam',\n",
       " 'bambi',\n",
       " 'banana',\n",
       " 'bananas',\n",
       " 'band',\n",
       " 'bandage',\n",
       " 'bandaid',\n",
       " 'bands',\n",
       " 'bang',\n",
       " 'banged',\n",
       " 'banging',\n",
       " 'bangle',\n",
       " 'bangs',\n",
       " 'banjo',\n",
       " 'bank',\n",
       " 'banks',\n",
       " 'bar',\n",
       " 'barbara',\n",
       " 'barbecue',\n",
       " 'barbed',\n",
       " 'barbell',\n",
       " 'barbie',\n",
       " 'barbies',\n",
       " 'bare',\n",
       " 'barely',\n",
       " 'bark',\n",
       " 'barked',\n",
       " 'barking',\n",
       " 'barkley',\n",
       " 'barks',\n",
       " 'barley',\n",
       " 'barlow',\n",
       " 'barn',\n",
       " 'barnacles',\n",
       " 'barnes',\n",
       " 'barney',\n",
       " 'barns',\n",
       " 'barnyard',\n",
       " 'barrel',\n",
       " 'barrette',\n",
       " 'barrier',\n",
       " 'barriers',\n",
       " 'bars',\n",
       " 'bart',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'basement',\n",
       " 'bases',\n",
       " 'basha',\n",
       " 'bashful',\n",
       " 'bashing',\n",
       " 'basically',\n",
       " 'basil',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'baskets',\n",
       " 'bat',\n",
       " 'bath',\n",
       " 'bathe',\n",
       " 'bathing',\n",
       " 'bathrobe',\n",
       " 'bathroom',\n",
       " 'baths',\n",
       " 'bathtub',\n",
       " 'batman',\n",
       " 'bats',\n",
       " 'batted',\n",
       " 'batter',\n",
       " 'battered',\n",
       " 'batteries',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'bausch',\n",
       " 'baxter',\n",
       " 'bay',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'bead',\n",
       " 'beads',\n",
       " 'beak',\n",
       " 'beam',\n",
       " 'bean',\n",
       " 'beans',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'bears',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beater',\n",
       " 'beaters',\n",
       " 'beating',\n",
       " 'beatles',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'beaver',\n",
       " 'bec',\n",
       " 'became',\n",
       " 'because',\n",
       " 'becky',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'bedbugs',\n",
       " 'bedroom',\n",
       " 'beds',\n",
       " 'bedspread',\n",
       " 'bedtime',\n",
       " 'bee',\n",
       " 'beef',\n",
       " 'beehive',\n",
       " 'beem',\n",
       " 'been',\n",
       " 'beep',\n",
       " 'beeper',\n",
       " 'beeping',\n",
       " 'beeps',\n",
       " 'beer',\n",
       " 'bees',\n",
       " 'beetle',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begged',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'behave',\n",
       " 'behaving',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'beings',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believes',\n",
       " 'bell',\n",
       " 'belle',\n",
       " 'bellied',\n",
       " 'bellies',\n",
       " 'bellows',\n",
       " 'bells',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'belongs',\n",
       " 'below',\n",
       " 'belt',\n",
       " 'belts',\n",
       " 'beluga',\n",
       " 'ben',\n",
       " 'bench',\n",
       " 'bend',\n",
       " 'bending',\n",
       " 'beneath',\n",
       " 'benjamin',\n",
       " 'benny',\n",
       " 'bent',\n",
       " 'berlin',\n",
       " 'berlioz',\n",
       " 'berries',\n",
       " 'berry',\n",
       " 'berserk',\n",
       " 'bert',\n",
       " 'bertram',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bestow',\n",
       " 'bet',\n",
       " 'betcha',\n",
       " 'beth',\n",
       " 'better',\n",
       " 'bettina',\n",
       " 'betty',\n",
       " 'between',\n",
       " 'beverly',\n",
       " 'beyond',\n",
       " 'biased',\n",
       " 'bib',\n",
       " 'bible',\n",
       " 'bibs',\n",
       " 'bicycle',\n",
       " 'bicycles',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bikes',\n",
       " 'bilbo',\n",
       " 'bill',\n",
       " 'billion',\n",
       " 'bills',\n",
       " 'billy',\n",
       " 'bin',\n",
       " 'binding',\n",
       " 'bing',\n",
       " 'bingo',\n",
       " 'bird',\n",
       " 'birdie',\n",
       " 'birdies',\n",
       " 'birds',\n",
       " 'birdy',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'biscuit',\n",
       " 'biscuits',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'bites',\n",
       " 'biting',\n",
       " 'bits',\n",
       " 'bitsy',\n",
       " 'bitty',\n",
       " 'bizarre',\n",
       " 'black',\n",
       " 'blackberries',\n",
       " 'blade',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blanche',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blankets',\n",
       " 'blast',\n",
       " 'bleachers',\n",
       " 'blech',\n",
       " 'bleed',\n",
       " 'bleeding',\n",
       " 'bleep',\n",
       " 'blender',\n",
       " 'blending',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blinking',\n",
       " 'blitzen',\n",
       " 'bloat',\n",
       " 'blob',\n",
       " 'block',\n",
       " 'blockbuster',\n",
       " 'blocked',\n",
       " 'blocks',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'blooded',\n",
       " 'bloody',\n",
       " 'blooming',\n",
       " 'blossoms',\n",
       " 'blot',\n",
       " 'blouse',\n",
       " 'blow',\n",
       " 'blower',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blows',\n",
       " 'blue',\n",
       " 'blueberries',\n",
       " 'blueberry',\n",
       " 'bluebird',\n",
       " 'bluegrass',\n",
       " 'blues',\n",
       " 'blum',\n",
       " 'boa',\n",
       " 'board',\n",
       " 'boards',\n",
       " 'boasting',\n",
       " 'boat',\n",
       " 'boats',\n",
       " 'bob',\n",
       " 'bobber',\n",
       " 'bobby',\n",
       " 'bobo',\n",
       " 'bock',\n",
       " 'bodies',\n",
       " 'body',\n",
       " 'bog',\n",
       " 'boil',\n",
       " 'boiled',\n",
       " 'boiling',\n",
       " 'boils',\n",
       " 'boink',\n",
       " 'bok',\n",
       " 'bologna',\n",
       " 'bolt',\n",
       " 'bom',\n",
       " 'bomber',\n",
       " 'bombs',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'bong',\n",
       " 'bonk',\n",
       " 'bonnet',\n",
       " 'bonnie',\n",
       " 'bonus',\n",
       " 'bony',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'bookcase',\n",
       " 'booked',\n",
       " 'booklet',\n",
       " 'books',\n",
       " 'bookshelf',\n",
       " 'bookstore',\n",
       " 'boom',\n",
       " 'boop',\n",
       " 'boost',\n",
       " 'booster',\n",
       " 'boot',\n",
       " 'bootie',\n",
       " 'booties',\n",
       " 'boots',\n",
       " 'booz',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'bosco',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bothering',\n",
       " 'bothers',\n",
       " 'bottle',\n",
       " 'bottled',\n",
       " 'bottles',\n",
       " 'bottom',\n",
       " 'bottomless',\n",
       " 'bottoms',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bouillon',\n",
       " 'boulder',\n",
       " 'bounce',\n",
       " 'bounced',\n",
       " 'bounces',\n",
       " 'bouncing',\n",
       " 'bouncy',\n",
       " 'bout',\n",
       " 'bow',\n",
       " 'bowels',\n",
       " 'bowie',\n",
       " 'bowl',\n",
       " 'bowling',\n",
       " 'bowls',\n",
       " 'bows',\n",
       " 'box',\n",
       " 'boxcar',\n",
       " 'boxcars',\n",
       " 'boxes',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boys',\n",
       " 'bozo',\n",
       " 'brace',\n",
       " 'bracelet',\n",
       " 'brad',\n",
       " 'brag',\n",
       " 'braids',\n",
       " 'brain',\n",
       " 'brake',\n",
       " 'brakes',\n",
       " 'bran',\n",
       " 'branch',\n",
       " 'branches',\n",
       " 'brand',\n",
       " 'bras',\n",
       " 'brat',\n",
       " 'brave',\n",
       " 'bravest',\n",
       " 'bravo',\n",
       " 'bread',\n",
       " 'breaded',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'breaks',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breathing',\n",
       " 'bree',\n",
       " 'breeze',\n",
       " 'brenda',\n",
       " 'brendan',\n",
       " 'brewster',\n",
       " 'brian',\n",
       " 'bribed',\n",
       " 'bribing',\n",
       " 'bricks',\n",
       " 'bride',\n",
       " 'bridge',\n",
       " 'bridges',\n",
       " 'brief',\n",
       " 'briefcase',\n",
       " 'briggs',\n",
       " 'bright',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'brink',\n",
       " 'brittany',\n",
       " 'bro',\n",
       " 'broadway',\n",
       " 'broccoli',\n",
       " 'brockton',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'bronco',\n",
       " 'broncos',\n",
       " 'brontosaurus',\n",
       " 'brook',\n",
       " 'brooks',\n",
       " 'broom',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brownie',\n",
       " 'brownies',\n",
       " 'brownish',\n",
       " 'browns',\n",
       " 'bruce',\n",
       " 'bruise',\n",
       " 'bruised',\n",
       " 'bruno',\n",
       " 'brush',\n",
       " 'brushes',\n",
       " 'brushing',\n",
       " 'brussels',\n",
       " 'brutality',\n",
       " 'bryce',\n",
       " 'bubba',\n",
       " 'bubble',\n",
       " 'bubbles',\n",
       " 'bubbly',\n",
       " 'buck',\n",
       " 'bucket',\n",
       " 'buckle',\n",
       " 'buckles',\n",
       " 'bucks',\n",
       " 'buddha',\n",
       " 'buddy',\n",
       " 'budge',\n",
       " 'buds',\n",
       " 'buffalo',\n",
       " 'buffers',\n",
       " 'bug',\n",
       " 'bugging',\n",
       " 'bugs',\n",
       " 'build',\n",
       " 'builder',\n",
       " 'building',\n",
       " 'buildings',\n",
       " 'built',\n",
       " 'bulb',\n",
       " 'bulk',\n",
       " 'bull',\n",
       " 'bulldog',\n",
       " 'bulldozer',\n",
       " 'bullets',\n",
       " 'bulls',\n",
       " 'bum',\n",
       " 'bumble',\n",
       " 'bump',\n",
       " 'bumped',\n",
       " 'bumper',\n",
       " 'bumping',\n",
       " 'bumps',\n",
       " 'bumpy',\n",
       " 'bun',\n",
       " 'bunch',\n",
       " 'bundled',\n",
       " 'bundles',\n",
       " 'bundy',\n",
       " 'bunk',\n",
       " 'bunks',\n",
       " 'bunnies',\n",
       " 'bunny',\n",
       " 'buns',\n",
       " 'bureau',\n",
       " 'burger',\n",
       " 'burglar',\n",
       " 'buried',\n",
       " 'burn',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'burns',\n",
       " 'burnt',\n",
       " 'burp',\n",
       " 'burrito',\n",
       " 'burrows',\n",
       " 'burst',\n",
       " 'burt',\n",
       " 'bury',\n",
       " 'bus',\n",
       " 'buses',\n",
       " 'bush',\n",
       " 'bushel',\n",
       " 'bushes',\n",
       " 'business',\n",
       " 'busted',\n",
       " 'buster',\n",
       " 'busts',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butch',\n",
       " 'butt',\n",
       " 'butter',\n",
       " 'butterflies',\n",
       " 'butterfly',\n",
       " 'buttering',\n",
       " 'button',\n",
       " 'buttons',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'buys',\n",
       " 'buzz',\n",
       " 'buzzer',\n",
       " 'buzzing',\n",
       " 'by',\n",
       " 'bye',\n",
       " 'c',\n",
       " 'ca',\n",
       " 'cab',\n",
       " 'cabbage',\n",
       " 'cabbages',\n",
       " 'cabin',\n",
       " 'cabinet',\n",
       " 'caboose',\n",
       " 'cackle',\n",
       " 'cadet',\n",
       " 'cafeteria',\n",
       " 'cage',\n",
       " 'cages',\n",
       " 'caitlin',\n",
       " 'cake',\n",
       " 'cakes',\n",
       " 'cal',\n",
       " 'calculator',\n",
       " 'calendar',\n",
       " 'calf',\n",
       " 'california',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camera',\n",
       " 'cameras',\n",
       " 'camp',\n",
       " 'camper',\n",
       " 'campfire',\n",
       " 'camping',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'canal',\n",
       " 'canary',\n",
       " 'cancel',\n",
       " 'canceled',\n",
       " 'candidates',\n",
       " 'candle',\n",
       " 'candles',\n",
       " 'candy',\n",
       " 'cane',\n",
       " 'canister',\n",
       " 'canned',\n",
       " 'cannon',\n",
       " 'cannot',\n",
       " 'canoe',\n",
       " 'canoes',\n",
       " 'cans',\n",
       " 'cant',\n",
       " 'cantaloupe',\n",
       " 'cap',\n",
       " 'capable',\n",
       " 'cape',\n",
       " 'caper',\n",
       " 'capes',\n",
       " 'capital',\n",
       " 'caplan',\n",
       " 'captain',\n",
       " 'capture',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardboard',\n",
       " 'cardinal',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'cares',\n",
       " 'cargo',\n",
       " 'carissa',\n",
       " 'carl',\n",
       " 'carle',\n",
       " 'carlo',\n",
       " 'carlos',\n",
       " 'carmen',\n",
       " 'carney',\n",
       " 'carnival',\n",
       " 'carol',\n",
       " 'carolina',\n",
       " 'carpet',\n",
       " 'carriage',\n",
       " 'carriages',\n",
       " 'carried',\n",
       " 'carrier',\n",
       " 'carries',\n",
       " 'carrot',\n",
       " 'carrots',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'cars',\n",
       " 'cart',\n",
       " 'carter',\n",
       " 'carton',\n",
       " 'cartoon',\n",
       " 'cartoons',\n",
       " 'cartridge',\n",
       " 'case',\n",
       " 'casey',\n",
       " 'cash',\n",
       " 'cassette',\n",
       " 'cassie',\n",
       " 'cassowary',\n",
       " 'castle',\n",
       " 'castles',\n",
       " 'cat',\n",
       " 'catalogs',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[DATASET]['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word in data[DATASET]['words'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fleece',\n",
       " 'gil',\n",
       " 'disinfectant',\n",
       " 'newer',\n",
       " 'madame',\n",
       " 'splashing',\n",
       " 'ninja',\n",
       " 'bec',\n",
       " 'alan',\n",
       " 'chairs',\n",
       " 'amanda',\n",
       " 'dairy',\n",
       " 'meatless',\n",
       " 'maize',\n",
       " 'hail',\n",
       " 'dub',\n",
       " 'snooze',\n",
       " 'foods',\n",
       " 'imports',\n",
       " 'seeking',\n",
       " 'alex',\n",
       " 'shown',\n",
       " 'wasted',\n",
       " 'yeh',\n",
       " 'born',\n",
       " 'floated',\n",
       " 'soles',\n",
       " 'whites',\n",
       " 'return',\n",
       " 'little',\n",
       " 'particularly',\n",
       " 'john',\n",
       " 'nurses',\n",
       " 'raw',\n",
       " 'rockwood',\n",
       " 'promised',\n",
       " 'compactor',\n",
       " 'power',\n",
       " 'eighteen',\n",
       " 'pours',\n",
       " 'sledding',\n",
       " 'lobster',\n",
       " 'august',\n",
       " 'knob',\n",
       " 'ladies',\n",
       " 'auto',\n",
       " 'lenard',\n",
       " 'sung',\n",
       " 'twins',\n",
       " 'orders',\n",
       " 'roof',\n",
       " 'bedbugs',\n",
       " 'mechanics',\n",
       " 'laundromat',\n",
       " 'shells',\n",
       " 'liking',\n",
       " 'keeper',\n",
       " 'clear',\n",
       " 'dankner',\n",
       " 'signs',\n",
       " 'raggedy',\n",
       " 'solar',\n",
       " 'talks',\n",
       " 'nina',\n",
       " 'stump',\n",
       " 'size',\n",
       " 'clue',\n",
       " 'intrusive',\n",
       " 'raven',\n",
       " 'spread',\n",
       " 'ago',\n",
       " 'wong',\n",
       " 'intersperse',\n",
       " 'elaine',\n",
       " 'chef',\n",
       " 'chickened',\n",
       " 'walls',\n",
       " 'al',\n",
       " 'trousers',\n",
       " 'es',\n",
       " 'cabbage',\n",
       " 'ruth',\n",
       " 'loaves',\n",
       " 'terrible',\n",
       " 'pox',\n",
       " 'complete',\n",
       " 'gaby',\n",
       " 'pouch',\n",
       " 'rosamund',\n",
       " 'blot',\n",
       " 'berries',\n",
       " 'knees',\n",
       " 'rogers',\n",
       " 'rocking',\n",
       " 'payday',\n",
       " 'oozing',\n",
       " 'boots',\n",
       " 'ice',\n",
       " 'yellowstone',\n",
       " 'mumble',\n",
       " 'river',\n",
       " 'clink',\n",
       " 'bringing',\n",
       " 'buttons',\n",
       " 'opened',\n",
       " 'poked',\n",
       " 'touch',\n",
       " 'trio',\n",
       " 'recipes',\n",
       " 'tow',\n",
       " 'weirder',\n",
       " 'lid',\n",
       " 'pampers',\n",
       " 'webbed',\n",
       " 'sink',\n",
       " 'combine',\n",
       " 'coin',\n",
       " 'perfectly',\n",
       " 'pounce',\n",
       " 'lagoon',\n",
       " 'wings',\n",
       " 'foxy',\n",
       " 'prize',\n",
       " 'alec',\n",
       " 'story',\n",
       " 'dandelions',\n",
       " 'unbutton',\n",
       " 'arthurs',\n",
       " 'comb',\n",
       " 'hoh',\n",
       " 'amara',\n",
       " 'paste',\n",
       " 'gather',\n",
       " 'tomorrow',\n",
       " 'cemetery',\n",
       " 'crusty',\n",
       " 'albuquerque',\n",
       " 'nicky',\n",
       " 'sad',\n",
       " 'tater',\n",
       " 'monkeys',\n",
       " 'krista',\n",
       " 'maam',\n",
       " 'wrapper',\n",
       " 'yourselves',\n",
       " 'jeep',\n",
       " 'sulfur',\n",
       " 'eagles',\n",
       " 'descent',\n",
       " 'potentially',\n",
       " 'unite',\n",
       " 'children',\n",
       " 'christ',\n",
       " 'bran',\n",
       " 'brand',\n",
       " 'happily',\n",
       " 'tusk',\n",
       " 'fooled',\n",
       " 'mucky',\n",
       " 'today',\n",
       " 'ladas',\n",
       " 'julius',\n",
       " 'mountain',\n",
       " 'shipwreck',\n",
       " 'sweeps',\n",
       " 'lunchtime',\n",
       " 'smiles',\n",
       " 'justine',\n",
       " 'send',\n",
       " 'underground',\n",
       " 'what',\n",
       " 'sesame',\n",
       " 'decent',\n",
       " 'rubbing',\n",
       " 'lander',\n",
       " 'pain',\n",
       " 'mayonnaise',\n",
       " 'roll',\n",
       " 'wrapping',\n",
       " 'highway',\n",
       " 'edna',\n",
       " 'lie',\n",
       " 'wan',\n",
       " 'teachers',\n",
       " 'saving',\n",
       " 'necessarily',\n",
       " 'basketball',\n",
       " 'raked',\n",
       " 'dr',\n",
       " 'knocking',\n",
       " 'elicited',\n",
       " 'nada',\n",
       " 'sweatpants',\n",
       " 'bundles',\n",
       " 'guild',\n",
       " 'perform',\n",
       " 'trails',\n",
       " 'nifty',\n",
       " 'meanwhile',\n",
       " 'wailed',\n",
       " 'peacock',\n",
       " 'swamp',\n",
       " 'whoop',\n",
       " 'sergeant',\n",
       " 'jolly',\n",
       " 'rested',\n",
       " 'types',\n",
       " 'tiki',\n",
       " 'filler',\n",
       " 'attitude',\n",
       " 'island',\n",
       " 'commodore',\n",
       " 'scratched',\n",
       " 'ding',\n",
       " 'mr',\n",
       " 'canary',\n",
       " 'goofy',\n",
       " 'eyeball',\n",
       " 'rabbits',\n",
       " 'bam',\n",
       " 'hugging',\n",
       " 'moons',\n",
       " 'costume',\n",
       " 'tiger',\n",
       " 'miner',\n",
       " 'hammers',\n",
       " 'raising',\n",
       " 'neighbor',\n",
       " 'peeked',\n",
       " 'cheesy',\n",
       " 'wrestling',\n",
       " 'farm',\n",
       " 'rudolf',\n",
       " 'prospectors',\n",
       " 'exactly',\n",
       " 'huh',\n",
       " 'hurry',\n",
       " 'pooped',\n",
       " 'reach',\n",
       " 'rectangular',\n",
       " 'worked',\n",
       " 'stones',\n",
       " 'peaches',\n",
       " 'drum',\n",
       " 'dong',\n",
       " 'grandpa',\n",
       " 'porsche',\n",
       " 'punching',\n",
       " 'tastes',\n",
       " 'of',\n",
       " 'mask',\n",
       " 'fir',\n",
       " 'telling',\n",
       " 'startled',\n",
       " 'mommies',\n",
       " 'peter',\n",
       " 'calls',\n",
       " 'wrap',\n",
       " 'whispering',\n",
       " 'switches',\n",
       " 'landed',\n",
       " 'plastered',\n",
       " 'anyhow',\n",
       " 'alabama',\n",
       " 'hatching',\n",
       " 'supermarket',\n",
       " 'brothers',\n",
       " 'formed',\n",
       " 'larry',\n",
       " 'postcard',\n",
       " 'sliced',\n",
       " 'lolly',\n",
       " 'stir',\n",
       " 'diane',\n",
       " 'kwanza',\n",
       " 'ribbit',\n",
       " 'trail',\n",
       " 'louder',\n",
       " 'connecticut',\n",
       " 'winning',\n",
       " 'television',\n",
       " 'rhyming',\n",
       " 'whoa',\n",
       " 'booklet',\n",
       " 'michelle',\n",
       " 'kathy',\n",
       " 'angel',\n",
       " 'keen',\n",
       " 'warped',\n",
       " 'nineteen',\n",
       " 'ambulance',\n",
       " 'loony',\n",
       " 'astonished',\n",
       " 'visitors',\n",
       " 'scientist',\n",
       " 'globe',\n",
       " 'tortillas',\n",
       " 'spigot',\n",
       " 'paddle',\n",
       " 'magnifying',\n",
       " 'turtle',\n",
       " 'duke',\n",
       " 'enjoying',\n",
       " 'recycle',\n",
       " 'astronomical',\n",
       " 'chirps',\n",
       " 'left',\n",
       " 'beem',\n",
       " 'eighty',\n",
       " 'choices',\n",
       " 'smokestack',\n",
       " 'photosynthesis',\n",
       " 'shh',\n",
       " 'door',\n",
       " 'percent',\n",
       " 'important',\n",
       " 'live',\n",
       " 'rocker',\n",
       " 'diet',\n",
       " 'uranus',\n",
       " 'minute',\n",
       " 'interesting',\n",
       " 'altogether',\n",
       " 'known',\n",
       " 'contact',\n",
       " 'felix',\n",
       " 'noises',\n",
       " 'sunshine',\n",
       " 'charley',\n",
       " 'polar',\n",
       " 'rode',\n",
       " 'belts',\n",
       " 'sewing',\n",
       " 'shyly',\n",
       " 'thrilled',\n",
       " 'nicholas',\n",
       " 'answers',\n",
       " 'jennifer',\n",
       " 'shark',\n",
       " 'beep',\n",
       " 'starfish',\n",
       " 'bun',\n",
       " 'mako',\n",
       " 'brad',\n",
       " 'clogged',\n",
       " 'donna',\n",
       " 'caw',\n",
       " 'diving',\n",
       " 'very',\n",
       " 'cloth',\n",
       " 'clouds',\n",
       " 'patience',\n",
       " 'mama',\n",
       " 'poking',\n",
       " 'haircut',\n",
       " 'invite',\n",
       " 'freckle',\n",
       " 'camping',\n",
       " 'joking',\n",
       " 'question',\n",
       " 'wee',\n",
       " 'cabinet',\n",
       " 'annie',\n",
       " 'hockey',\n",
       " 'poh',\n",
       " 'burt',\n",
       " 'between',\n",
       " 'stepping',\n",
       " 'resting',\n",
       " 'sneeze',\n",
       " 'sir',\n",
       " 'lump',\n",
       " 'brian',\n",
       " 'whatever',\n",
       " 'receding',\n",
       " 'vicuna',\n",
       " 'sandwich',\n",
       " 'creepy',\n",
       " 'exhausted',\n",
       " 'pew',\n",
       " 'gremlins',\n",
       " 'save',\n",
       " 'marbles',\n",
       " 'cape',\n",
       " 'nativity',\n",
       " 'reh',\n",
       " 'timmy',\n",
       " 'accent',\n",
       " 'flick',\n",
       " 'underarm',\n",
       " 'bring',\n",
       " 'doc',\n",
       " 'have',\n",
       " 'flip',\n",
       " 'toy',\n",
       " 'frustrating',\n",
       " 'sword',\n",
       " 'sizes',\n",
       " 'bid',\n",
       " 'blob',\n",
       " 'delight',\n",
       " 'operated',\n",
       " 'dropping',\n",
       " 'raindrops',\n",
       " 'hang',\n",
       " 'igloo',\n",
       " 'coming',\n",
       " 'go',\n",
       " 'tonight',\n",
       " 'golem',\n",
       " 'bulls',\n",
       " 'egg',\n",
       " 'weeks',\n",
       " 'vicky',\n",
       " 'chewed',\n",
       " 'sale',\n",
       " 'yahoo',\n",
       " 'jacket',\n",
       " 'unbuttoned',\n",
       " 'thousandth',\n",
       " 'singing',\n",
       " 'pages',\n",
       " 'sturdy',\n",
       " 'pool',\n",
       " 'nie',\n",
       " 'ar',\n",
       " 'oy',\n",
       " 'collapsed',\n",
       " 'boo',\n",
       " 'chow',\n",
       " 'forms',\n",
       " 'mcdonalds',\n",
       " 'sorely',\n",
       " 'pontoons',\n",
       " 'jingle',\n",
       " 'storyteller',\n",
       " 'headstart',\n",
       " 'hydrants',\n",
       " 'jerked',\n",
       " 'jump',\n",
       " 'bars',\n",
       " 'pour',\n",
       " 'bear',\n",
       " 'paintings',\n",
       " 'flack',\n",
       " 'flying',\n",
       " 'bundy',\n",
       " 'dogs',\n",
       " 'snazzy',\n",
       " 'tad',\n",
       " 'restless',\n",
       " 'poor',\n",
       " 'chip',\n",
       " 'checker',\n",
       " 'hug',\n",
       " 'vegetable',\n",
       " 'operate',\n",
       " 'married',\n",
       " 'dirty',\n",
       " 'bob',\n",
       " 'parade',\n",
       " 'guatemala',\n",
       " 'patch',\n",
       " 'teton',\n",
       " 'silliest',\n",
       " 'express',\n",
       " 'morgan',\n",
       " 'date',\n",
       " 'workable',\n",
       " 'sold',\n",
       " 'wagged',\n",
       " 'major',\n",
       " 'cub',\n",
       " 'derrick',\n",
       " 'stared',\n",
       " 'missing',\n",
       " 'shorter',\n",
       " 'judge',\n",
       " 'wallet',\n",
       " 'waited',\n",
       " 'choking',\n",
       " 'dopey',\n",
       " 'extra',\n",
       " 'journey',\n",
       " 'weigh',\n",
       " 'easier',\n",
       " 'halves',\n",
       " 'intonation',\n",
       " 'produce',\n",
       " 'polished',\n",
       " 'siberian',\n",
       " 'cardboard',\n",
       " 'waffle',\n",
       " 'fan',\n",
       " 'sting',\n",
       " 'suppose',\n",
       " 'pair',\n",
       " 'souvenir',\n",
       " 'stroller',\n",
       " 'bib',\n",
       " 'meat',\n",
       " 'allegiance',\n",
       " 'south',\n",
       " 'shopper',\n",
       " 'however',\n",
       " 'parachuting',\n",
       " 'patched',\n",
       " 'horns',\n",
       " 'stool',\n",
       " 'mey',\n",
       " 'colts',\n",
       " 'touchdown',\n",
       " 'lamppost',\n",
       " 'pounds',\n",
       " 'queen',\n",
       " 'bracelet',\n",
       " 'seekonk',\n",
       " 'bleed',\n",
       " 'climbed',\n",
       " 'dew',\n",
       " 'prepared',\n",
       " 'stabbed',\n",
       " 'after',\n",
       " 'ariel',\n",
       " 'azaleas',\n",
       " 'hums',\n",
       " 'johnnie',\n",
       " 'corduroy',\n",
       " 'pierre',\n",
       " 'cock',\n",
       " 'gorgeous',\n",
       " 'idaho',\n",
       " 'goodbye',\n",
       " 'itchy',\n",
       " 'sara',\n",
       " 'war',\n",
       " 'royal',\n",
       " 'remaking',\n",
       " 'pause',\n",
       " 'eleven',\n",
       " 'film',\n",
       " 'finished',\n",
       " 'hopscotch',\n",
       " 'election',\n",
       " 'burns',\n",
       " 'leo',\n",
       " 'naughty',\n",
       " 'checks',\n",
       " 'given',\n",
       " 'prayers',\n",
       " 'rangy',\n",
       " 'bertram',\n",
       " 'thing',\n",
       " 'recital',\n",
       " 'screwed',\n",
       " 'petunias',\n",
       " 'pokey',\n",
       " 'parlor',\n",
       " 'earn',\n",
       " 'rhoda',\n",
       " 'cotton',\n",
       " 'clothes',\n",
       " 'windows',\n",
       " 'soon',\n",
       " 'soiled',\n",
       " 'aqua',\n",
       " 'burglar',\n",
       " 'neither',\n",
       " 'bald',\n",
       " 'butterflies',\n",
       " 'gently',\n",
       " 'raved',\n",
       " 'accidentally',\n",
       " 'ninth',\n",
       " 'tasha',\n",
       " 'conductor',\n",
       " 'stole',\n",
       " 'nose',\n",
       " 'house',\n",
       " 'tripping',\n",
       " 'measured',\n",
       " 'lala',\n",
       " 'hind',\n",
       " 'miles',\n",
       " 'sailed',\n",
       " 'muppets',\n",
       " 'rainy',\n",
       " 'indigestion',\n",
       " 'exercising',\n",
       " 'seem',\n",
       " 'bright',\n",
       " 'paul',\n",
       " 'groups',\n",
       " 'humans',\n",
       " 'diana',\n",
       " 'gulp',\n",
       " 'stopped',\n",
       " 'darla',\n",
       " 'service',\n",
       " 'olives',\n",
       " 'tooth',\n",
       " 'absolutely',\n",
       " 'pinched',\n",
       " 'ravioli',\n",
       " 'wilmington',\n",
       " 'tuck',\n",
       " 'housewife',\n",
       " 'blank',\n",
       " 'suns',\n",
       " 'wheat',\n",
       " 'fawn',\n",
       " 'brings',\n",
       " 'dirk',\n",
       " 'scribble',\n",
       " 'butterfly',\n",
       " 'frightened',\n",
       " 'brakes',\n",
       " 'tuesday',\n",
       " 'truth',\n",
       " 'jill',\n",
       " 'trip',\n",
       " 'maxie',\n",
       " 'beside',\n",
       " 's',\n",
       " 'shotgun',\n",
       " 'wound',\n",
       " 'stupid',\n",
       " 'mumma',\n",
       " 'names',\n",
       " 'scrooge',\n",
       " 'lightening',\n",
       " 'instead',\n",
       " 'fall',\n",
       " 'willy',\n",
       " 'policemen',\n",
       " 'row',\n",
       " 'holy',\n",
       " 'fraser',\n",
       " 'tissue',\n",
       " 'typewriter',\n",
       " 'sodas',\n",
       " 'now',\n",
       " 'flamingos',\n",
       " 'followed',\n",
       " 'dazed',\n",
       " 'horse',\n",
       " 'trusty',\n",
       " 'skate',\n",
       " 'board',\n",
       " 'cares',\n",
       " 'buttering',\n",
       " 'walruses',\n",
       " 'smelled',\n",
       " 'register',\n",
       " 'troll',\n",
       " 'columbus',\n",
       " 'manage',\n",
       " 'branch',\n",
       " 'catalogues',\n",
       " 'mould',\n",
       " 'pupil',\n",
       " 'dances',\n",
       " 'helps',\n",
       " 'coins',\n",
       " 'somebody',\n",
       " 'pinkie',\n",
       " 'oscar',\n",
       " 'strings',\n",
       " 'swimmers',\n",
       " 'caterpillars',\n",
       " 'volcano',\n",
       " 'daddy',\n",
       " 'hardware',\n",
       " 'rubs',\n",
       " 'kool',\n",
       " 'boyfriend',\n",
       " 'huntsman',\n",
       " 'babe',\n",
       " 'oliver',\n",
       " 'hope',\n",
       " 'eleventh',\n",
       " 'yuck',\n",
       " 'gaudy',\n",
       " 'lynn',\n",
       " 'none',\n",
       " 'excellent',\n",
       " 'outta',\n",
       " 'them',\n",
       " 'elastic',\n",
       " 'erases',\n",
       " 'tipping',\n",
       " 'bandaid',\n",
       " 'plant',\n",
       " 'lemonade',\n",
       " 'adams',\n",
       " 'rappa',\n",
       " 'robbers',\n",
       " 'sheet',\n",
       " 'their',\n",
       " 'chantilly',\n",
       " 'ginger',\n",
       " 'punched',\n",
       " 'tales',\n",
       " 'plain',\n",
       " 'dinah',\n",
       " 'tool',\n",
       " 'maine',\n",
       " 'caveman',\n",
       " 'fries',\n",
       " 'hell',\n",
       " 'limited',\n",
       " 'swam',\n",
       " 'stink',\n",
       " 'doubt',\n",
       " 'fact',\n",
       " 'tour',\n",
       " 'thursday',\n",
       " 'cinnamon',\n",
       " 'searching',\n",
       " 'tyrannosaurus',\n",
       " 'represent',\n",
       " 'midget',\n",
       " 'evil',\n",
       " 'eater',\n",
       " 'dozen',\n",
       " 'boil',\n",
       " 'egyptian',\n",
       " 'travel',\n",
       " 'sieve',\n",
       " 'science',\n",
       " 'lovely',\n",
       " 'prison',\n",
       " 'sues',\n",
       " 'salon',\n",
       " 'noodle',\n",
       " 'teasing',\n",
       " 'those',\n",
       " 'troubles',\n",
       " 'bom',\n",
       " 'asleep',\n",
       " 'dribble',\n",
       " 'leader',\n",
       " 'earl',\n",
       " 'won',\n",
       " 'thomas',\n",
       " 'inches',\n",
       " 'pussy',\n",
       " 'offering',\n",
       " 'gills',\n",
       " 'breaded',\n",
       " 'harvey',\n",
       " 'everyday',\n",
       " 'ogre',\n",
       " 'catalogs',\n",
       " 'recognized',\n",
       " 'slurp',\n",
       " 'jumper',\n",
       " 'boat',\n",
       " 'acrobat',\n",
       " 'path',\n",
       " 'flopping',\n",
       " 'fore',\n",
       " 'pork',\n",
       " 'dead',\n",
       " 'orthography',\n",
       " 'dig',\n",
       " 'emmy',\n",
       " 'messes',\n",
       " 'stranger',\n",
       " 'expect',\n",
       " 'mackerel',\n",
       " 'peppermint',\n",
       " 'roommate',\n",
       " 'er',\n",
       " 'stinky',\n",
       " 'shorts',\n",
       " 'roy',\n",
       " 'first',\n",
       " 'hola',\n",
       " 'canoe',\n",
       " 'scooter',\n",
       " 'further',\n",
       " 'include',\n",
       " 'broccoli',\n",
       " 'flour',\n",
       " 'fourth',\n",
       " 'pliers',\n",
       " 'super',\n",
       " 'bean',\n",
       " 'sniffles',\n",
       " 'seaweed',\n",
       " 'nails',\n",
       " 'pecan',\n",
       " 'erin',\n",
       " 'stew',\n",
       " 'thanksgiving',\n",
       " 'treetop',\n",
       " 'gigantic',\n",
       " 'addition',\n",
       " 'trestle',\n",
       " 'rambler',\n",
       " 'fireworks',\n",
       " 'barrette',\n",
       " 'aha',\n",
       " 'hoot',\n",
       " 'houses',\n",
       " 'jeremiah',\n",
       " 'band',\n",
       " 'difference',\n",
       " 'sherry',\n",
       " 'baker',\n",
       " 'defend',\n",
       " 'babies',\n",
       " 'brother',\n",
       " 'hungry',\n",
       " 'baggy',\n",
       " 'disk',\n",
       " 'upside',\n",
       " 'awfully',\n",
       " 'help',\n",
       " 'screw',\n",
       " 'mice',\n",
       " 'settled',\n",
       " 'somewhat',\n",
       " 'speed',\n",
       " 'older',\n",
       " 'pitcher',\n",
       " 'goldfish',\n",
       " 'chucked',\n",
       " 'melons',\n",
       " 'flames',\n",
       " 'slammed',\n",
       " 'trapeze',\n",
       " 'ian',\n",
       " 'bleep',\n",
       " 'turvy',\n",
       " 'boards',\n",
       " 'wearing',\n",
       " 'drift',\n",
       " 'roosters',\n",
       " 'moe',\n",
       " 'boasting',\n",
       " 'carissa',\n",
       " 'nicest',\n",
       " 'glockenspiel',\n",
       " 'duh',\n",
       " 'tug',\n",
       " 'etcetera',\n",
       " 'yourself',\n",
       " 'reluctant',\n",
       " 'council',\n",
       " 'flapped',\n",
       " 'dreaming',\n",
       " 'household',\n",
       " 'wont',\n",
       " 'directly',\n",
       " 'imagined',\n",
       " 'whoever',\n",
       " 'high',\n",
       " 'davids',\n",
       " 'having',\n",
       " 'mush',\n",
       " 'k',\n",
       " 'bang',\n",
       " 'sugars',\n",
       " 'attached',\n",
       " 'provoke',\n",
       " 'charles',\n",
       " 'matching',\n",
       " 'fantasy',\n",
       " 'exchange',\n",
       " 'leafy',\n",
       " 'yow',\n",
       " 'disneyworld',\n",
       " 'clogs',\n",
       " 'pushed',\n",
       " 'nana',\n",
       " 'homemade',\n",
       " 'jaws',\n",
       " 'tata',\n",
       " 'ark',\n",
       " 'pin',\n",
       " 'dreams',\n",
       " 'outer',\n",
       " 'neighborhood',\n",
       " 'self',\n",
       " 'liver',\n",
       " 'magna',\n",
       " 'lined',\n",
       " 'nephews',\n",
       " 'bows',\n",
       " 'grouch',\n",
       " 'worse',\n",
       " 'brain',\n",
       " 'marie',\n",
       " 'turned',\n",
       " 'garbage',\n",
       " 'bottom',\n",
       " 'parallel',\n",
       " 'neptune',\n",
       " 'apparently',\n",
       " 'hates',\n",
       " 'dumptruck',\n",
       " 'counts',\n",
       " 'potato',\n",
       " 'bedspread',\n",
       " 'case',\n",
       " 'ricky',\n",
       " 'beauty',\n",
       " 'battery',\n",
       " 'transformed',\n",
       " 'wakes',\n",
       " 'model',\n",
       " 'thrasher',\n",
       " 'roars',\n",
       " 'anyone',\n",
       " 'bumped',\n",
       " 'dream',\n",
       " 'pacific',\n",
       " 'sure',\n",
       " 'unless',\n",
       " 'money',\n",
       " 'lab',\n",
       " 'goin',\n",
       " 'gross',\n",
       " 'towers',\n",
       " 'file',\n",
       " 'impressed',\n",
       " 'pulp',\n",
       " 'crawl',\n",
       " 'messing',\n",
       " 'spin',\n",
       " 'arrives',\n",
       " 'sick',\n",
       " 'spare',\n",
       " 'speeding',\n",
       " 'vividly',\n",
       " 'tutu',\n",
       " 'toothbrushes',\n",
       " 'danube',\n",
       " 'returned',\n",
       " 'porcupines',\n",
       " 'pee',\n",
       " 'warned',\n",
       " 'packed',\n",
       " 'stephen',\n",
       " 'um',\n",
       " 'open',\n",
       " 'watching',\n",
       " 'r',\n",
       " 'slyly',\n",
       " 'panting',\n",
       " 'celebrate',\n",
       " 'controller',\n",
       " 'propeller',\n",
       " 'too',\n",
       " 'spanking',\n",
       " 'jackets',\n",
       " 'page',\n",
       " 'yep',\n",
       " 'pans',\n",
       " 'terry',\n",
       " 'internet',\n",
       " 'punk',\n",
       " 'lean',\n",
       " 'perch',\n",
       " 'beat',\n",
       " 'ramp',\n",
       " 'rolly',\n",
       " 'yak',\n",
       " 'yawning',\n",
       " 'punky',\n",
       " 'kleenex',\n",
       " 'fiddle',\n",
       " 'tail',\n",
       " 'recording',\n",
       " 'zooming',\n",
       " 'permanent',\n",
       " 'overflowing',\n",
       " 'closet',\n",
       " 'paw',\n",
       " 'plains',\n",
       " 'beeping',\n",
       " 'just',\n",
       " 'tofu',\n",
       " 'barley',\n",
       " 'grocery',\n",
       " 'crash',\n",
       " 'obviously',\n",
       " 'raincoat',\n",
       " 'so',\n",
       " 'barnacles',\n",
       " 'loves',\n",
       " 'roger',\n",
       " 'ruins',\n",
       " 'demanded',\n",
       " 'colors',\n",
       " 'op',\n",
       " 'meatballs',\n",
       " 'cha',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TD.pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ['the', 'b;ah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7300"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[DATASET]['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pretraining', 'fry_1980', 'ewfg'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "\n",
    "    data = pickle.load(open(PATH + \"/\" + checkpoint, \"rb\"))\n",
    "    for dataset in data.keys():\n",
    "        \n",
    "        all_words.extend(data[dataset]['words'])\n",
    "\n",
    "all_words = list(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orthpad changed to 0 because onehot encodings were selected for orthography\n",
      "Words of phonological length 1 pass reconstruction test\n",
      "Words of phonological length 2 pass reconstruction test\n",
      "Words of phonological length 3 pass reconstruction test\n",
      "Words of phonological length 4 pass reconstruction test\n",
      "Words of phonological length 5 pass reconstruction test\n",
      "Words of phonological length 6 pass reconstruction test\n",
      "Words of phonological length 7 pass reconstruction test\n",
      "Words of phonological length 8 pass reconstruction test\n",
      "Words of phonological length 9 pass reconstruction test\n",
      "Words of phonological length 10 pass reconstruction test\n",
      "Words of phonological length 11 pass reconstruction test\n",
      "Words of phonological length 12 pass reconstruction test\n",
      "Words of phonological length 13 pass reconstruction test\n",
      "Words of phonological length 14 pass reconstruction test\n",
      "Words of phonological length 15 pass reconstruction test\n",
      "Representations initialized. Done.\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'pretraining'\n",
    "\n",
    "\n",
    "TD = Traindata(all_words, phonpath = \"../data/phonreps.csv\", oneletter=True)\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "\n",
    "    data = pickle.load(open(PATH + \"/\" + checkpoint, \"rb\"))\n",
    "    epoch = re.search(r'epoch_(.*?)\\.pkl', checkpoint).group(1)\n",
    "    model_id = re.search(r'pretraining_(.*?)\\_epoch', checkpoint).group(1)\n",
    "\n",
    "\n",
    "    # First clone the tensors to avoid modifying the originals\n",
    "    phon_preds = data[\"pretraining\"][\"phon_predictions\"].clone()\n",
    " \n",
    "\n",
    "    with open('pretraining_results_1/stringform/pretrain_words_stringform_results_' + model_id + '_' + 'epoch' + '_' + epoch + '.csv', 'w') as f:\n",
    "\n",
    "        f.write(\"model_id, epoch, training_phase, condition, word, phon_pred, phon_target\\n\")\n",
    "\n",
    "        for i in range(len(data[DATASET]['words'])):\n",
    "\n",
    "            word = data[DATASET]['words'][i]        \n",
    "            phon_pred = \"-\".join(convert_numeric_prediction(phon_preds[i], phonreps=reps))\n",
    "            phon_target = \"-\".join(TD.cmudict[word])\n",
    "\n",
    "            f.write(\"{model_id}, {epoch}, {training_phase}, {condition}, {word}, {phon_pred}, {phon_target}\\n\".format(\n",
    "                model_id = model_id,\n",
    "                epoch = epoch,\n",
    "                training_phase = 'pretrain',\n",
    "                condition = 'pretrain',\n",
    "                word = word,\n",
    "                phon_pred = phon_pred,\n",
    "                phon_target = phon_target\n",
    "            )\n",
    "        )\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fry Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'fry_1980'\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "\n",
    "    data = pickle.load(open(PATH + \"/\" + checkpoint, \"rb\"))\n",
    "    epoch = re.search(r'epoch_(.*?)\\.pkl', checkpoint).group(1)\n",
    "    model_id = re.search(r'pretraining_(.*?)\\_epoch', checkpoint).group(1)\n",
    "\n",
    "    # First clone the tensors to avoid modifying the originals\n",
    "    phon_preds = data[DATASET][\"phon_predictions\"].clone()\n",
    "\n",
    "    with open('pretraining_results_1/stringform/fry_words_stringform_results_' + model_id + '_' + 'epoch' + '_' + epoch + '.csv', 'w') as f:\n",
    "\n",
    "        f.write(\"model_id, epoch, training_phase, condition, word, phon_pred, phon_target\\n\")\n",
    "\n",
    "        for i in range(len(data[DATASET]['words'])):\n",
    "\n",
    "            word = data[DATASET]['words'][i]        \n",
    "            phon_pred = \"-\".join(convert_numeric_prediction(phon_preds[i], phonreps=reps))\n",
    "            phon_target = \"-\".join(TD.cmudict[word])\n",
    "\n",
    "            f.write(\"{model_id}, {epoch}, {training_phase}, {condition}, {word}, {phon_pred}, {phon_target}\\n\".format(\n",
    "                model_id = model_id,\n",
    "                epoch = epoch,\n",
    "                training_phase = 'pretrain',\n",
    "                condition = 'pretrain',\n",
    "                word = word,\n",
    "                phon_pred = phon_pred,\n",
    "                phon_target = phon_target\n",
    "            )\n",
    "        )\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWFG Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7300 is out of bounds for dimension 0 with size 7300",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data[DATASET][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m     18\u001b[0m     word \u001b[38;5;241m=\u001b[39m data[DATASET][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m'\u001b[39m][i]        \n\u001b[0;32m---> 19\u001b[0m     phon_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(convert_numeric_prediction(\u001b[43mphon_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, phonreps\u001b[38;5;241m=\u001b[39mreps))\n\u001b[1;32m     20\u001b[0m     phon_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(TD\u001b[38;5;241m.\u001b[39mcmudict[word])\n\u001b[1;32m     22\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{model_id}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{epoch}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{training_phase}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{condition}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{word}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{phon_pred}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{phon_target}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     23\u001b[0m         model_id \u001b[38;5;241m=\u001b[39m model_id,\n\u001b[1;32m     24\u001b[0m         epoch \u001b[38;5;241m=\u001b[39m epoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7300 is out of bounds for dimension 0 with size 7300"
     ]
    }
   ],
   "source": [
    "DATASET = 'ewfg'\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "\n",
    "    data = pickle.load(open(PATH + \"/\" + checkpoint, \"rb\"))\n",
    "    epoch = re.search(r'epoch_(.*?)\\.pkl', checkpoint).group(1)\n",
    "    model_id = re.search(r'pretraining_(.*?)\\_epoch', checkpoint).group(1)\n",
    "\n",
    "    # First clone the tensors to avoid modifying the originals\n",
    "    phon_preds = data[DATASET][\"phon_predictions\"].clone()\n",
    "\n",
    "    with open('pretraining_results_1/stringform/ewfg_words_stringform_results_' + model_id + '_' + 'epoch' + '_' + epoch + '.csv', 'w') as f:\n",
    "\n",
    "        f.write(\"model_id, epoch, training_phase, condition, word, phon_pred, phon_target\\n\")\n",
    "\n",
    "        for i in range(len(data[DATASET]['words'])):\n",
    "\n",
    "            word = data[DATASET]['words'][i]        \n",
    "            phon_pred = \"-\".join(convert_numeric_prediction(phon_preds[i], phonreps=reps))\n",
    "            phon_target = \"-\".join(TD.cmudict[word])\n",
    "\n",
    "            f.write(\"{model_id}, {epoch}, {training_phase}, {condition}, {word}, {phon_pred}, {phon_target}\\n\".format(\n",
    "                model_id = model_id,\n",
    "                epoch = epoch,\n",
    "                training_phase = 'pretrain',\n",
    "                condition = 'pretrain',\n",
    "                word = word,\n",
    "                phon_pred = phon_pred,\n",
    "                phon_target = phon_target\n",
    "            )\n",
    "        )\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
