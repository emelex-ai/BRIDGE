{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1RVNEzSxD2feCeIA7ZaYetfwKP8Gw3MJR","timestamp":1680742266468}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["'''\n","Changelog\n","\n","-  (4/2/2023)\n","   * Implemented global attention for producing grapheme/phoneme embedding. The previous\n","     approach (concatenate all timesteps into a single vector + feedforward) was\n","     memory-intensive and risked contaminating the embeddings w/ \n","     padding.\n","   * Removed some redundant layers in both encoder and decoder\n","   * _generate_ still doesn't work; need to discuss tokenizer w/ group\n","\n","   --- Luke \n","''';\n","\n","'''\n","TODO:\n","Spin up Spot Instance with hosted notebook: Nathan\n","Training Loop must be completed: Luke\n","Finish the Generate Function\n","Tensorboard probably to be used in some capacity: Nathan/Luke in the future\n","\n","--- Nathan\n","'''"],"metadata":{"id":"LWJ5tuuiRf-f","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1680742278853,"user_tz":240,"elapsed":8,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}},"outputId":"5ee4337f-21b8-47a7-c314-1c2614c4e9e4"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nTODO:\\nSpin up Spot Instance with hosted notebook: Nathan\\nTraining Loop must be completed: Luke\\nFinish the Generate Function\\nTensorboard probably to be used in some capacity: Nathan/Luke in the future\\n\\n--- Nathan\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["### Get Data\n","\n","Load some data into the content folder. This should be in our shared ConnTextUL folder. You may need to move the shared folder to a location in your drive with the same full path as indicated here. Or, we can devise a more efficient way to sahre data in the future.\n","\n"],"metadata":{"id":"L0Jqgdh9LtIN"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount('/gdrive', force_remount=True)\n","!ln -s \"/gdrive/My Drive/Projects/Modeling Reading Programs/ConnTextUL/data\" \"/content\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Ew3Y4czLsIm","executionInfo":{"status":"ok","timestamp":1680742314659,"user_tz":240,"elapsed":18117,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}},"outputId":"b12c2855-b8c4-4cbb-8b6c-0872bc548dab"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive not mounted, so nothing to flush and unmount.\n","Mounted at /gdrive\n"]}]},{"cell_type":"markdown","source":["Download and install huggingface transformer module for the CanineTokenizer"],"metadata":{"id":"XXwghuHIQ-VO"}},{"cell_type":"code","source":["#https://pypi.org/project/transformers/\n","!pip install transformers\n","from transformers import CanineTokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zag7rLp6F2GG","executionInfo":{"status":"ok","timestamp":1680742332086,"user_tz":240,"elapsed":17431,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}},"outputId":"0107e721-90e7-4cf4-be7e-7353c45a3d86"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.3 transformers-4.27.4\n"]}]},{"cell_type":"code","execution_count":213,"metadata":{"id":"Zixda65wfwMe","executionInfo":{"status":"ok","timestamp":1680748137300,"user_tz":240,"elapsed":272,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}}},"outputs":[],"source":["from torch.utils.data import Dataset\n","import pandas as pd\n","import torch as pt\n","import numpy as np"]},{"cell_type":"code","source":["class CUDA_Dict(dict):\n","    def to(self,device):\n","        return {key:self[key].to(device) for key in self.keys()}"],"metadata":{"id":"BMnmxo7_ZtMh","executionInfo":{"status":"ok","timestamp":1680748494568,"user_tz":240,"elapsed":195,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}}},"execution_count":226,"outputs":[]},{"cell_type":"code","source":["class CharacterTokenizer:\n","    def __init__(self,list_of_characters):\n","\n","        self.char_2_idx = {'[BOW]':0,'[EOW]':1,'[CLS]':2,'[UNK]':3,'[PAD]':4}\n","        for idx,character in enumerate(list_of_characters): self.char_2_idx[character] = idx+5\n","        self.idx_2_char = {self.char_2_idx[char]:char for char in self.char_2_idx}\n","\n","    def __len__(self): return len(self.char_2_idx)\n","\n","    def encode(self,list_of_strings):\n","        assert isinstance(list_of_strings,str) or (isinstance(list_of_strings,list) \\\n","                 and all(isinstance(string,str) for string in list_of_strings))\n","        if isinstance(list_of_strings,str): list_of_strings = [list_of_strings]\n","\n","        lengths = [len(string) for string in list_of_strings]\n","        max_length = max(lengths)\n","\n","        pad = lambda string: ['[BOS]'] + list(string) + (max_length - len(string)) * ['[PAD]'] + ['[EOS]']\n","        list_of_strings = list(map(pad,list_of_strings))\n","\n","        tokens = pt.zeros((len(list_of_strings),2 + max_length),dtype=pt.long)\n","        for idx,string in enumerate(list_of_strings):\n","            for jdx,char in enumerate(string):\n","                tokens[idx,jdx] = self.char_2_idx.get(char,3)\n","\n","        attention_mask = (pt.arange(max_length+2)[None] >= (pt.Tensor(lengths)+2)[:,None]).float()\n","        return CUDA_Dict({'input_ids':tokens,'attention_mask':attention_mask.bool()})\n","            \n","\n","    def decode(self,list_of_ints):\n","        assert isinstance(list_of_ints,int) or (isinstance(list_of_ints,int) \\\n","                 and all(isinstance(ints,int) for ints in list_of_ints))\n","        if isinstance(list_of_ints,int): list_of_ints = [list_of_ints]\n","\n","        outputs = [''.join([self.idx_2_char.get(i) for i in ints]) for ints in list_of_ints]"],"metadata":{"id":"Eb6AGvZfIHel","executionInfo":{"status":"ok","timestamp":1680748591961,"user_tz":240,"elapsed":248,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}}},"execution_count":234,"outputs":[]},{"cell_type":"code","source":["class GraphoneDataset(Dataset):\n","    \"\"\"GraphoneDataset\n","\n","    Dataset of word/phoneme pairs. The phonemes are predicted from the DeepPhonemizer. \n","    The final embeddings output from this dataset come from Google's Canine model.\n","\n","    \"\"\"\n","    def __init__(self):\n","\n","        # The orthography and phonology are stored in separate files\n","        self.letters = pd.read_csv(\"/gdrive/MyDrive/data/orth_phon_mappings/all_orth.csv\", header=None)[0].to_numpy()\n","        self.phons = pd.read_csv(\"/gdrive/MyDrive/data/orth_phon_mappings/all_phon.csv\", header=None)[0].to_numpy()\n","        self.max_len = max( max(map(len, self.letters)), max(map(len, self.phons)) )\n","\n","    def __len__(self):\n","        length = len(self.letters)  \n","        assert length == len(self.phons), \"Dataset size mismatch!\"\n","\n","        return length  \n","\n","    def __getitem__(self, idx):\n","        orth_string = self.letters[idx]\n","        phon_string = self.phons[idx]        \n","        return (orth_string,phon_string)\n","\n","def collate(batches,orthography_tokenizer,phoneme_tokenizer):\n","      orthography = [batch[0] for batch in batches]\n","      phonology = [batch[1] for batch in batches]\n","\n","      return {'orthography':orthography_tokenizer.encode(orthography),'phonology':phoneme_tokenizer.encode(phonology)}"],"metadata":{"id":"JoeOsgnpFCNu","executionInfo":{"status":"ok","timestamp":1680748137507,"user_tz":240,"elapsed":2,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}}},"execution_count":215,"outputs":[]},{"cell_type":"code","source":["class Encoder(pt.nn.Module):\n","    def __init__(self, d_model=768, nhead=1, num_layers=1):\n","        super(Encoder, self).__init__()\n","        encoder_layer = pt.nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n","        self.transformer_encoder = pt.nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","\n","    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n","        output = self.transformer_encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n","        return output\n","    \n","class Decoder(pt.nn.Module):\n","    def __init__(self, d_model=768, nhead=1, num_layers=1):\n","        super().__init__()\n","        decoder_layer = pt.nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n","        self.transformer_decoder = pt.nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n","\n","    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n","        output = self.transformer_decoder(tgt, memory, \n","                                            tgt_mask=tgt_mask, \n","                                            memory_mask=memory_mask, \n","                                            tgt_key_padding_mask=tgt_key_padding_mask, \n","                                            memory_key_padding_mask=memory_key_padding_mask)\n","\n","        return output"],"metadata":{"id":"C5HHY76YNWDT","executionInfo":{"status":"ok","timestamp":1680744999517,"user_tz":240,"elapsed":195,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["class GraphoneModel(pt.nn.Module):\n","    def __init__(self, orth_vocab_size, phon_orth_vocab_size, d_model=768, nhead=1, num_layers=1, max_seq_len=21):\n","        super().__init__()\n","\n","        self.orthography_embedding = pt.nn.Embedding(orth_vocab_size,d_model)\n","        self.phonology_embedding = pt.nn.Embedding(phon_orth_vocab_size,d_model)\n","        self.position_embedding = pt.nn.Embedding(max_seq_len,d_model)\n","\n","        self.vocab_sizes = (orth_vocab_size,phon_orth_vocab_size)\n","        self.d_model = d_model\n","        self.max_seq_len = max_seq_len\n","\n","        self.global_embedding = pt.nn.Parameter(pt.randn((1,1,self.d_model))/self.d_model**.5,requires_grad=True)\n","\n","        self.grapheme_encoder = Encoder(d_model=d_model, nhead=nhead, num_layers=num_layers)\n","        self.phoneme_encoder = Encoder(d_model=d_model, nhead=nhead, num_layers=num_layers)\n","\n","        self.gp_multihead_attention = pt.nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead, batch_first=True)\n","        self.pg_multihead_attention = pt.nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead, batch_first=True)\n","\n","        self.transformer_mixer = Encoder(d_model=self.d_model, nhead=nhead, num_layers=num_layers)\n","        self.reduce = pt.nn.Linear(self.d_model,self.d_model)\n","\n","        self.grapheme_decoder = Decoder(d_model=self.d_model, nhead=nhead, num_layers=num_layers)\n","        self.linear_grapheme_decoder = pt.nn.Linear(self.d_model, self.vocab_sizes[0])\n","\n","        self.phoneme_decoder = Decoder(d_model=self.d_model, nhead=nhead, num_layers=num_layers)\n","        self.linear_phoneme_decoder = pt.nn.Linear(self.d_model, self.vocab_sizes[1])\n","\n","    def generate_triangular_mask(self, size, device):\n","        mask = pt.triu(pt.ones((size, size), dtype=pt.bool,device=device),1)\n","        return mask\n","\n","    def embed_tokens(self,tokens,mode='o'):\n","        assert mode in ['o','p']\n","\n","        if mode == 'o':\n","           return self.orthography_embedding(tokens) + self.position_embedding.weight[None,:tokens.shape[1]]\n","        else:\n","           return self.phonology_embedding(tokens) + self.position_embedding.weight[None,:tokens.shape[1]]\n","\n","    def embed(self, graphemes, grapheme_padding_mask, phonemes, phoneme_padding_mask):\n","        graphemes,phonemes = self.embed_tokens(graphemes,'o'),self.embed_tokens(phonemes,'p')\n","\n","        grapheme_encoding = self.grapheme_encoder(graphemes,src_key_padding_mask=grapheme_padding_mask)\n","        phoneme_encoding = self.phoneme_encoder(phonemes,src_key_padding_mask=phoneme_padding_mask)\n","\n","        gp_encoding = self.gp_multihead_attention(grapheme_encoding, phoneme_encoding, phoneme_encoding,\n","                                                  key_padding_mask = phoneme_padding_mask)[0]\n","        pg_encoding = self.pg_multihead_attention(phoneme_encoding, grapheme_encoding, grapheme_encoding,\n","                                                  key_padding_mask = grapheme_padding_mask)[0]\n","\n","        gp_pg = pt.cat((gp_encoding, pg_encoding), dim=1) + pt.cat((grapheme_encoding, phoneme_encoding), dim=1)\n","        gp_pg_padding_mask = pt.cat((grapheme_padding_mask,phoneme_padding_mask),dim=-1)\n","\n","        gp_pg = pt.cat((self.global_embedding.repeat(gp_pg.shape[0],1,1),gp_pg),dim=1)\n","        gp_pg_padding_mask = pt.cat((pt.zeros((gp_pg.shape[0],1),device=gp_pg.device,dtype=pt.bool),gp_pg_padding_mask),dim=-1)\n","        mixed_encoding = self.transformer_mixer(gp_pg,src_key_padding_mask=gp_pg_padding_mask) \n","\n","        final_encoding = self.reduce(mixed_encoding[:,0]).unsqueeze(-2)\n","        return final_encoding,graphemes,phonemes\n","\n","\n","    def forward(self, graphemes, grapheme_padding_mask, phonemes, phoneme_padding_mask):\n","        mixed_encoding,graphemes,phonemes = self.embed(graphemes, grapheme_padding_mask, phonemes, phoneme_padding_mask)\n","\n","        grapheme_ar_mask = self.generate_triangular_mask(graphemes.shape[1],graphemes.device)\n","        grapheme_output = self.grapheme_decoder(graphemes, mixed_encoding, tgt_mask = grapheme_ar_mask)\n","\n","        phoneme_ar_mask = self.generate_triangular_mask(phonemes.shape[1],phonemes.device)\n","        phoneme_output = self.grapheme_decoder(phonemes, mixed_encoding, tgt_mask = phoneme_ar_mask)\n","\n","        grapheme_token_logits = self.linear_grapheme_decoder(grapheme_output)\n","        phoneme_token_logits = self.linear_phoneme_decoder(phoneme_output)\n","        return grapheme_token_logits, phoneme_token_logits\n","\n","\n","    def generate(self, graphemes, grapheme_mask, phonemes, phoneme_mask, max_new_tokens=21):\n","        self.eval()\n","        device = next(self.parameters()).device\n","\n","        with pt.no_grad():\n","            prompt_encoding = self.embed(graphemes, grapheme_mask, phonemes, phoneme_mask)[0]\n","\n","        mask = self.generate_triangular_mask(self.max_seq_len, device)\n","\n","        generated_tokens = pt.zeros((2,prompt_encoding.shape[0]),dtype=pt.long)\n","        generated_embeddings = self.embed_tokens(generated_tokens)[:,:,None]\n","        generated_tokens = generated_tokens[:,:,None]\n","\n","        dummy_mask = pt.zeros((1,15),device=device)\n","        dummy_mask[0,0] = 1\n","\n","        for step in range(max_new_tokens):\n","            step_mask = mask[:step+1, :step+1]\n","\n","            with pt.no_grad():\n","                grapheme_token_logits = self.linear_grapheme_decoder(self.grapheme_decoder(generated_embeddings[0], prompt_encoding, tgt_mask=step_mask))\n","                phoneme_token_logits = self.linear_phoneme_decoder(self.phoneme_decoder(generated_embeddings[1], prompt_encoding, tgt_mask=step_mask))\n","\n","            last_token_logits = (grapheme_token_logits[:,-1, :],phoneme_token_logits[:,-1, :])\n","            last_token_probs = (\n","                                    pt.softmax(last_token_logits[0], dim=-1),\n","                                    pt.softmax(last_token_logits[1], dim=-1)\n","                                )\n","\n","            new_grapheme_token = pt.multinomial(last_token_probs[0], num_samples=1)\n","            new_phoneme_token = pt.multinomial(last_token_probs[1], num_samples=1)\n","\n","            generated_tokens = pt.cat((generated_tokens,pt.stack((new_grapheme_token,new_phoneme_token),dim=0)),dim=2)\n","\n","            generated_embeddings = pt.cat((generated_embeddings,pt.stack(\n","                                                (\n","                                                    self.embed_tokens(new_grapheme_token,'o'),\n","                                                    self.embed_tokens(new_phoneme_token,'p')\n","                                                  ),\n","                                            dim=0)),dim=2)\n","            \n","        return generated_tokens"],"metadata":{"id":"cwf0vKAPFF9k","executionInfo":{"status":"ok","timestamp":1680746456897,"user_tz":240,"elapsed":414,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}}},"execution_count":163,"outputs":[]},{"cell_type":"code","source":["if pt.cuda.is_available():\n","   device = pt.device('cuda:0')\n","else:\n","   device = pt.device('cpu')"],"metadata":{"id":"WFhSUdhsVnr0","executionInfo":{"status":"ok","timestamp":1680747192517,"user_tz":240,"elapsed":147,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}}},"execution_count":175,"outputs":[]},{"cell_type":"code","source":["ds = GraphoneDataset()\n","\n","orthography_tokenizer = CharacterTokenizer(set(''.join(ds.letters)))\n","phonology_tokenizer = CharacterTokenizer(set(''.join(ds.phons)))\n","\n","train,validation = pt.utils.data.random_split(ds,(int(.8 * len(ds)),len(ds) - int(.8 * len(ds))))\n","\n","collate_fn = lambda x: collate(x,orthography_tokenizer,phonology_tokenizer)\n","train_loader = pt.utils.data.DataLoader(train, batch_size=64, shuffle=True,collate_fn = collate_fn)\n","val_loader = pt.utils.data.DataLoader(validation, batch_size=64, collate_fn = collate_fn)"],"metadata":{"id":"H0ilxpDlTdFL","executionInfo":{"status":"ok","timestamp":1680748596714,"user_tz":240,"elapsed":243,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}}},"execution_count":235,"outputs":[]},{"cell_type":"code","source":["### Luke: And voila! It works. \n","gm = GraphoneModel(len(orthography_tokenizer),len(phonology_tokenizer), max_seq_len=100)\n","_ = gm.embed(pt.randint(0,10,(11, 21)), pt.zeros((11,21),dtype=pt.bool), pt.randint(0,10,(11, 21)), pt.zeros((11,21),dtype=pt.bool))\n","_ = gm(pt.randint(0,10,(11, 21)), pt.zeros((11,21),dtype=pt.bool), pt.randint(0,10,(11, 21)), pt.zeros((11,21),dtype=pt.bool))\n","_ = gm.generate(pt.randint(0,10,(11, 21)), pt.zeros((11,21),dtype=pt.bool), pt.randint(0,10,(11, 21)), pt.zeros((11,21),dtype=pt.bool))"],"metadata":{"id":"6tJ0h6-kFRZb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680748515054,"user_tz":240,"elapsed":3079,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}},"outputId":"11c90e6a-aba3-4f17-ce0c-456e0b675a35"},"execution_count":230,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/nn/modules/activation.py:1144: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n","  return torch._native_multi_head_attention(\n"]}]},{"cell_type":"code","source":["import tqdm\n","\n","num_epochs = 100\n","pbar = tqdm.tqdm(range(num_epochs),position=0)\n","\n","gm.to(device)\n","opt = pt.optim.Adam(gm.parameters(),1e-3)\n","\n","for epoch in pbar:\n","    gm.train()\n","    for batch in train_loader:\n","        orthography,phonology = batch['orthography'].to(device),batch['phonology'].to(device)\n","        logits = gm(orthography['input_ids'],orthography['attention_mask'],\n","                      phonology['input_ids'],phonology['attention_mask'])\n","        \n","        loss = pt.nn.CrossEntropyLoss(ignore_index=4)(logits[0].transpose(1,2),orthography['input_ids']) \n","        loss = loss + pt.nn.CrossEntropyLoss(ignore_index=4)(logits[1].transpose(1,2),phonology['input_ids'])\n","\n","        loss.backward()\n","        opt.step()\n","        opt.zero_grad()\n","\n","    gm.eval()\n","    with pt.no_grad():\n","       for batch in val_loader:\n","           orthography,phonology = batch['orthography'].to(device),batch['phonology'].to(device)\n","           logits = gm(orthography['input_ids'],orthography['attention_mask'],\n","                      phonology['input_ids'],phonology['attention_mask'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"id":"ferrk1sk2OLn","executionInfo":{"status":"error","timestamp":1680748726823,"user_tz":240,"elapsed":428,"user":{"displayName":"Luke Van Popering","userId":"02456184849863928744"}},"outputId":"41da7877-6f66-43ec-9852-594c56ff97af"},"execution_count":243,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/100 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-243-fb83785d6b26>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0morthography\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphonology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'orthography'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phonology'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         logits = gm(orthography['input_ids'],orthography['attention_mask'],\n\u001b[0m\u001b[1;32m     14\u001b[0m                       phonology['input_ids'],phonology['attention_mask'])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-163-9a7fadd82c0c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graphemes, grapheme_padding_mask, phonemes, phoneme_padding_mask)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphemes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrapheme_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphonemes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoneme_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mmixed_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraphemes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphonemes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphemes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrapheme_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphonemes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoneme_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mgrapheme_ar_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_triangular_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphemes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraphemes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-163-9a7fadd82c0c>\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, graphemes, grapheme_padding_mask, phonemes, phoneme_padding_mask)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mphoneme_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphoneme_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphonemes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mphoneme_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         gp_encoding = self.gp_multihead_attention(grapheme_encoding, phoneme_encoding, phoneme_encoding,\n\u001b[0m\u001b[1;32m     49\u001b[0m                                                   key_padding_mask = phoneme_padding_mask)[0]\n\u001b[1;32m     50\u001b[0m         pg_encoding = self.pg_multihead_attention(phoneme_encoding, grapheme_encoding, grapheme_encoding,\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1190\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_separate_proj_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5187\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0min_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is False but in_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5188\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_in_projection_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5189\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5190\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is True but q_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4774\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4775\u001b[0m                 \u001b[0mb_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_kv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4776\u001b[0;31m             \u001b[0mq_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4777\u001b[0m             \u001b[0mkv_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_kv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_kv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4778\u001b[0m             \u001b[0;31m# reshape to 2, E and not E, 2 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}