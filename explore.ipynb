{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to /Users/nathan/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from dataset import ConnTextULDataset\n",
    "from model import Model\n",
    "import torch as torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in [20, 50, 100, 250, 500, 1000]:\n",
    "    new_df = df['word_raw'][torch.randint(low=0, high=50000, size=(size,)).tolist()]\n",
    "    new_df.to_csv(f\"data/data_test{size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"data/data_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19766, 44181, 15386, 24120, 19357])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ConnTextULDataset()\n",
    "m = Model(len(ds.character_tokenizer),\n",
    "          len(ds.phonology_tokenizer),\n",
    "          d_model=64,\n",
    "          nhead=4)\n",
    "m.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word =  ['sam', 'sat', 'in', 'the', 'sand']\n",
      "orth['enc_input_ids'] =  tensor([[ 0, 26,  6,  8,  1,  4],\n",
      "        [ 0, 26,  6, 18,  1,  4],\n",
      "        [ 0, 11, 21,  1,  4,  4],\n",
      "        [ 0, 18, 42, 36,  1,  4],\n",
      "        [ 0, 26,  6, 21, 38,  1]])\n",
      "orth['enc_pad_mask'] =  tensor([[False, False, False, False, False,  True],\n",
      "        [False, False, False, False, False,  True],\n",
      "        [False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False,  True],\n",
      "        [False, False, False, False, False, False]])\n",
      "orth['dec_input_ids'] =  tensor([[ 0, 26,  6,  8,  4],\n",
      "        [ 0, 26,  6, 18,  4],\n",
      "        [ 0, 11, 21,  4,  4],\n",
      "        [ 0, 18, 42, 36,  4],\n",
      "        [ 0, 26,  6, 21, 38]])\n",
      "orth['dec_pad_mask'] =  tensor([[False, False, False, False,  True],\n",
      "        [False, False, False, False,  True],\n",
      "        [False, False, False,  True,  True],\n",
      "        [False, False, False, False,  True],\n",
      "        [False, False, False, False, False]])\n",
      "phon['enc_input_ids'] =  [[tensor([31]), tensor([2, 7]), tensor([14, 15, 17, 22, 29]), tensor([ 0,  9, 14]), tensor([32]), tensor([33])], [tensor([31]), tensor([2, 7]), tensor([14, 15, 17, 22, 29]), tensor([2, 6]), tensor([32]), tensor([33])], [tensor([31]), tensor([14, 15, 18]), tensor([ 2,  9, 14]), tensor([32]), tensor([33]), tensor([33])], [tensor([31]), tensor([ 1,  7, 14]), tensor([14, 16, 21]), tensor([32]), tensor([33]), tensor([33])], [tensor([31]), tensor([2, 7]), tensor([14, 15, 17, 22, 29]), tensor([ 2,  9, 14]), tensor([ 2,  6, 14]), tensor([32])]]\n",
      "phon['enc_pad_mask'] =  tensor([[False, False, False, False, False,  True],\n",
      "        [False, False, False, False, False,  True],\n",
      "        [False, False, False, False,  True,  True],\n",
      "        [False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False]])\n",
      "phon['dec_input_ids'] =  [[tensor([31]), tensor([2, 7]), tensor([14, 15, 17, 22, 29]), tensor([ 0,  9, 14]), tensor([33])], [tensor([31]), tensor([2, 7]), tensor([14, 15, 17, 22, 29]), tensor([2, 6]), tensor([33])], [tensor([31]), tensor([14, 15, 18]), tensor([ 2,  9, 14]), tensor([33]), tensor([33])], [tensor([31]), tensor([ 1,  7, 14]), tensor([14, 16, 21]), tensor([33]), tensor([33])], [tensor([31]), tensor([2, 7]), tensor([14, 15, 17, 22, 29]), tensor([ 2,  9, 14]), tensor([ 2,  6, 14])]]\n",
      "phon['dec_pad_mask'] =  tensor([[False, False, False, False,  True],\n",
      "        [False, False, False, False,  True],\n",
      "        [False, False, False,  True,  True],\n",
      "        [False, False, False,  True,  True],\n",
      "        [False, False, False, False, False]])\n",
      "phon['targets'] =  tensor([[[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "          0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2]],\n",
      "\n",
      "        [[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "          0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2]],\n",
      "\n",
      "        [[0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2]],\n",
      "\n",
      "        [[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "          0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]])\n"
     ]
    }
   ],
   "source": [
    "idx = 10040\n",
    "num_words = 5\n",
    "word = ds.words[idx:idx+num_words]\n",
    "print(\"word = \", word)\n",
    "batch = ds[idx:idx+num_words]\n",
    "#print(\"batch = \", batch)\n",
    "orth, phon = batch['orthography'].to('cpu'), batch['phonology'].to('cpu')\n",
    "print(\"orth['enc_input_ids'] = \", orth['enc_input_ids'])\n",
    "print(\"orth['enc_pad_mask'] = \", orth['enc_pad_mask'])\n",
    "print(\"orth['dec_input_ids'] = \", orth['dec_input_ids'])\n",
    "print(\"orth['dec_pad_mask'] = \", orth['dec_pad_mask'])\n",
    "print(\"phon['enc_input_ids'] = \", phon['enc_input_ids'])\n",
    "print(\"phon['enc_pad_mask'] = \", phon['enc_pad_mask'])\n",
    "print(\"phon['dec_input_ids'] = \", phon['dec_input_ids'])\n",
    "print(\"phon['dec_pad_mask'] = \", phon['dec_pad_mask'])\n",
    "print(\"phon['targets'] = \", phon['targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = m(orth_enc_input=orth['enc_input_ids'],\n",
    "      orth_enc_pad_mask=orth['enc_pad_mask'],\n",
    "      orth_dec_input=orth['dec_input_ids'],\n",
    "      orth_dec_pad_mask=orth['dec_pad_mask'],\n",
    "      phon_enc_input=phon['enc_input_ids'],\n",
    "      phon_enc_pad_mask=phon['enc_pad_mask'],\n",
    "      phon_dec_input=phon['dec_input_ids'],\n",
    "      phon_dec_pad_mask=phon['dec_pad_mask']\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z['orth'].shape torch.Size([5, 49, 5])\n",
      "z['orth'] =  tensor([[[ 0.1693, -0.3138,  0.3945,  0.4023, -0.2128],\n",
      "         [-0.1762, -0.2139, -0.7959, -0.3276, -0.8687],\n",
      "         [-0.2521,  0.6397,  0.7131,  0.9635,  0.4533],\n",
      "         ...,\n",
      "         [ 0.1149,  0.4284, -0.1474,  1.3147,  0.2178],\n",
      "         [ 0.9473,  0.4294,  0.6466,  0.5680,  0.0916],\n",
      "         [ 0.0937,  0.5946,  0.7476,  0.0094,  0.6407]],\n",
      "\n",
      "        [[ 0.1141, -0.3748,  0.3429,  0.1574, -0.2646],\n",
      "         [-0.1272, -0.1478, -0.6973, -0.2399, -0.7895],\n",
      "         [-0.2942,  0.5909,  0.6714,  0.1885,  0.4278],\n",
      "         ...,\n",
      "         [ 0.1854,  0.5123, -0.0753,  0.9547,  0.3033],\n",
      "         [ 0.8905,  0.3622,  0.5781,  0.3989, -0.0041],\n",
      "         [ 0.2335,  0.7719,  0.8947,  0.1949,  0.8043]],\n",
      "\n",
      "        [[ 0.2735,  0.1292,  0.4252,  0.1254, -0.1035],\n",
      "         [-0.2312,  0.3869,  0.0136, -1.3735, -0.9628],\n",
      "         [-0.2011,  1.1976,  1.2021,  0.7942,  0.4181],\n",
      "         ...,\n",
      "         [ 0.1078,  0.1932,  0.0524,  0.8915,  0.2176],\n",
      "         [ 0.9242,  0.2486, -0.1911,  0.2626,  0.0945],\n",
      "         [ 0.3199,  0.8245,  1.6957, -0.0600,  0.9047]],\n",
      "\n",
      "        [[ 0.2471,  0.1888,  0.0839,  0.0202, -0.1627],\n",
      "         [-0.1153,  0.1680, -0.6190, -1.1587, -0.8913],\n",
      "         [-0.2646,  0.1496,  0.9979,  0.2092,  0.4420],\n",
      "         ...,\n",
      "         [ 0.1184,  0.1917, -0.7368,  0.5789,  0.1092],\n",
      "         [ 0.8790,  0.2590,  0.1747,  0.0924,  0.0149],\n",
      "         [ 0.1179,  0.2379,  0.7351, -0.0601,  0.6523]],\n",
      "\n",
      "        [[ 0.3250, -0.1275,  0.5753,  0.2935,  0.7224],\n",
      "         [-0.1689, -0.1611, -0.7863,  0.4068,  0.2146],\n",
      "         [-0.0881,  0.7732,  0.8604,  1.0658,  0.1987],\n",
      "         ...,\n",
      "         [ 0.1762,  0.4669, -0.1033,  0.7049,  0.0421],\n",
      "         [ 0.9401,  0.4250,  0.6490, -0.1772, -0.3316],\n",
      "         [ 0.0559,  0.4973,  0.6739,  0.6771,  1.3927]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "orth['enc_input_ids'].shape =  torch.Size([5, 6])\n",
      "orth['enc_input_ids'][:,1:] =  tensor([[26,  6,  8,  1,  4],\n",
      "        [26,  6, 18,  1,  4],\n",
      "        [11, 21,  1,  4,  4],\n",
      "        [18, 42, 36,  1,  4],\n",
      "        [26,  6, 21, 38,  1]])\n",
      "torch.argmax(z['orth'], dim=1) =  tensor([[18, 35, 45,  9, 18],\n",
      "        [18, 35, 45, 23, 18],\n",
      "        [18,  2, 48,  9, 48],\n",
      "        [18,  3, 38, 23, 10],\n",
      "        [18, 35, 23,  2, 48]])\n",
      "accuracy =  tensor(0.2000)\n"
     ]
    }
   ],
   "source": [
    "print(\"z['orth'].shape\", z['orth'].shape)\n",
    "print(\"z['orth'] = \", z['orth'])\n",
    "print(\"orth['enc_input_ids'].shape = \", orth['enc_input_ids'].shape)\n",
    "labels = orth['enc_input_ids'][:,1:]\n",
    "print(\"orth['enc_input_ids'][:,1:] = \", labels)\n",
    "preds = torch.argmax(z['orth'], dim=1)\n",
    "print(\"torch.argmax(z['orth'], dim=1) = \", preds)\n",
    "accuracy = (preds == labels).sum() / len(labels)\n",
    "print(\"accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds == labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z['phon'].shape torch.Size([1, 2, 4, 33])\n",
      "z['phon'] =  tensor([[[[ 4.4194e-01,  1.2137e-02, -1.1275e+00, -1.3524e-01,  6.3349e-02,\n",
      "           -2.1050e-01, -9.0739e-02,  3.0333e-01,  5.6287e-01, -1.5716e-03,\n",
      "           -4.5574e-01, -8.8808e-01, -7.1200e-01, -3.6442e-01,  7.7940e-02,\n",
      "           -1.1434e-01,  3.8295e-01, -5.4414e-01,  4.1145e-01,  2.9466e-01,\n",
      "            3.3463e-01, -2.9968e-02, -7.9627e-01,  1.0003e+00, -1.3511e-01,\n",
      "            1.0474e+00, -7.4798e-02,  2.0223e-01, -2.5267e-01,  4.4629e-01,\n",
      "           -2.7202e-02, -4.7697e-01, -4.0632e-01],\n",
      "          [ 7.3698e-01,  8.1904e-02,  6.9783e-01, -1.5817e-01,  8.8913e-01,\n",
      "           -3.7205e-01, -1.2592e-01,  1.2707e-01,  1.7307e-01,  2.5315e-01,\n",
      "           -1.6076e-01,  3.8544e-01, -5.7465e-01, -7.1618e-01, -8.9231e-01,\n",
      "           -5.9913e-01, -3.8458e-01,  9.2893e-02,  1.3562e-01,  4.3413e-01,\n",
      "            1.0148e-01,  1.6369e-01, -1.5533e-01,  3.9790e-01, -1.9901e-02,\n",
      "            3.8274e-01,  9.4589e-02,  4.4247e-01, -7.1658e-01,  5.7099e-01,\n",
      "           -4.6511e-01,  1.8199e-01, -1.3451e-01],\n",
      "          [ 7.6317e-01,  6.1599e-01,  1.2847e-01,  3.0220e-01,  1.0287e+00,\n",
      "            6.5214e-01, -1.2834e-01,  6.6172e-01,  2.0579e-01,  4.4686e-01,\n",
      "           -8.1047e-01,  9.9459e-02, -9.2888e-01, -7.9728e-01, -4.1217e-01,\n",
      "           -3.5965e-02,  1.9654e-01, -8.0664e-01, -8.1127e-01,  5.4127e-01,\n",
      "           -2.9452e-01, -2.7105e-01, -7.7490e-01,  4.3423e-01,  1.4548e-01,\n",
      "           -4.0843e-01, -1.6619e-01,  7.3791e-01, -1.2662e+00, -6.7386e-01,\n",
      "            1.6885e-01, -4.7113e-02,  1.6506e-01],\n",
      "          [ 4.7252e-01,  1.0143e-01, -2.7045e-01, -8.1715e-02,  6.3961e-01,\n",
      "            5.6352e-01, -2.0884e-01,  9.6811e-01, -4.5370e-01,  5.5363e-01,\n",
      "           -6.0811e-01,  4.2300e-02, -1.0678e+00, -5.5507e-01,  6.9242e-01,\n",
      "            5.7591e-01, -6.6930e-03, -7.8298e-01, -8.0180e-01,  4.6426e-01,\n",
      "           -2.6852e-01, -6.3184e-01, -5.5849e-01,  4.4380e-02,  6.3126e-01,\n",
      "           -3.3354e-01, -1.3223e-01,  6.3155e-01, -4.2745e-01, -4.7519e-01,\n",
      "            7.7706e-01,  5.9871e-01,  3.1433e-01]],\n",
      "\n",
      "         [[ 9.8696e-01, -2.6378e-01,  2.3596e-01,  6.6254e-01, -1.9409e-01,\n",
      "           -7.8220e-01, -1.0239e+00,  6.3048e-01, -1.1721e-01,  1.4005e-01,\n",
      "           -4.4182e-01, -2.6614e-01, -8.9335e-02, -9.1511e-01, -2.7059e-01,\n",
      "           -1.1936e+00,  1.3401e+00, -2.1598e-01,  4.0915e-01, -3.1213e-01,\n",
      "            2.4303e-01,  2.0617e-01, -5.9141e-01,  4.6475e-02, -3.7313e-01,\n",
      "            2.0697e-03,  5.7910e-01, -1.0814e+00,  3.0084e-01, -8.2681e-01,\n",
      "            4.2340e-02, -3.2863e-01, -1.0736e+00],\n",
      "          [-5.8803e-01, -4.2684e-01, -3.5978e-01,  7.4431e-01, -8.1110e-01,\n",
      "           -2.1331e-01, -7.4900e-01, -1.2795e-01,  5.4836e-01,  6.2540e-01,\n",
      "           -4.0505e-01, -8.0897e-01, -5.3420e-01, -1.2529e-01, -2.1185e-01,\n",
      "            3.5994e-01,  1.0670e+00, -1.1461e-02, -2.2455e-01,  6.0371e-01,\n",
      "            4.5858e-01,  3.7534e-01, -1.0564e+00,  2.2625e-01, -9.8975e-01,\n",
      "           -1.6241e-01,  4.1808e-01, -2.5653e-01, -1.3695e-01, -1.4705e+00,\n",
      "            1.2783e-02,  2.7858e-01,  7.2379e-02],\n",
      "          [ 6.1295e-01, -6.0160e-02, -3.5900e-01,  3.5104e-01, -5.4039e-01,\n",
      "            8.6590e-01, -3.3836e-01,  3.7957e-01, -4.8124e-01,  6.6177e-01,\n",
      "           -1.2401e+00,  3.2924e-02, -6.0907e-01,  5.4467e-01,  1.5743e-01,\n",
      "           -8.4735e-01,  6.7150e-02,  1.4116e-01,  4.9234e-01,  1.2134e+00,\n",
      "            9.6406e-01,  1.3624e+00, -1.3971e+00, -2.8130e-03,  6.7727e-02,\n",
      "           -4.9513e-01, -9.6479e-01, -8.5311e-01,  2.2457e-01, -1.2246e+00,\n",
      "           -9.4762e-01,  3.3113e-01, -1.0932e-01],\n",
      "          [ 3.9322e-01, -2.1491e-01,  3.0202e-01, -5.3477e-02,  1.0120e-01,\n",
      "            7.1607e-01,  4.3224e-01, -2.1435e-01,  5.5517e-01,  6.3975e-01,\n",
      "           -2.2153e-02,  7.8546e-01,  2.4075e-01,  4.4637e-01,  3.0457e-03,\n",
      "            1.4509e-01,  8.2804e-01, -5.1331e-01,  7.6806e-01,  3.3436e-01,\n",
      "            1.2652e-02,  8.5741e-01, -1.6880e+00,  1.8133e-01,  8.6929e-03,\n",
      "           -6.2761e-01, -1.6737e-01, -1.0705e+00,  7.6095e-02, -2.7709e-01,\n",
      "           -9.9872e-01,  8.0371e-01,  3.0582e-01]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "          0, 0, 0, 1, 0, 1, 0, 1, 1, 0],\n",
       "         [0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "          0, 0, 0, 1, 0, 1, 0, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "          0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "         [0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "          1, 0, 0, 0, 0, 1, 1, 0, 1, 0]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"z['phon'].shape\", z['phon'].shape)\n",
    "print(\"z['phon'] = \", z['phon'])\n",
    "torch.argmax(z['phon'], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = m(orthography['enc_input_ids'], orthography['enc_pad_mask'],\n",
    "                orthography['dec_input_ids'], orthography['dec_pad_mask'],\n",
    "                phonology['enc_input_ids'], phonology['enc_pad_mask'],\n",
    "                phonology['dec_input_ids'], phonology['dec_pad_mask'])\n",
    "        \n",
    "orth_loss = pt.nn.CrossEntropyLoss(ignore_index=4)(logits['orth'], orthography['enc_input_ids'][:,1:]) \n",
    "phon_loss = pt.nn.CrossEntropyLoss(ignore_index=2)(logits['phon'], phonology['targets'])\n",
    "loss = orth_loss + phon_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phon_output.shape =  torch.Size([1, 1, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 1, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 1, 33])\n",
      "phon_output.shape =  torch.Size([1, 2, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 2, 33])\n",
      "phon_output.shape =  torch.Size([1, 3, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 3, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 3, 33])\n",
      "phon_output.shape =  torch.Size([1, 4, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 4, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 4, 33])\n",
      "phon_output.shape =  torch.Size([1, 5, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 5, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 5, 33])\n",
      "phon_output.shape =  torch.Size([1, 6, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 6, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 6, 33])\n",
      "phon_output.shape =  torch.Size([1, 7, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 7, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 7, 33])\n",
      "phon_output.shape =  torch.Size([1, 8, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 8, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 8, 33])\n",
      "phon_output.shape =  torch.Size([1, 9, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 9, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 9, 33])\n",
      "phon_output.shape =  torch.Size([1, 10, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 10, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 10, 33])\n",
      "phon_output.shape =  torch.Size([1, 11, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 11, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 11, 33])\n",
      "phon_output.shape =  torch.Size([1, 12, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 12, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 12, 33])\n",
      "phon_output.shape =  torch.Size([1, 13, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 13, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 13, 33])\n",
      "phon_output.shape =  torch.Size([1, 14, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 14, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 14, 33])\n",
      "phon_output.shape =  torch.Size([1, 15, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 15, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 15, 33])\n",
      "phon_output.shape =  torch.Size([1, 16, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 16, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 16, 33])\n",
      "phon_output.shape =  torch.Size([1, 17, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 17, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 17, 33])\n",
      "phon_output.shape =  torch.Size([1, 18, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 18, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 18, 33])\n",
      "phon_output.shape =  torch.Size([1, 19, 64])\n",
      "phonology_token_logits.shape =  torch.Size([1, 19, 66])\n",
      "phonology_token_logits.shape =  torch.Size([1, 2, 19, 33])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[16, 40,  4,  0, 16, 15,  5, 45,  7, 31, 19, 16, 42, 40,  8, 15,  0, 16,\n",
       "         42]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_prime = m.generate(orth_enc_input=orth, \n",
    "                     orth_enc_pad_mask=torch.zeros_like(orth).bool(), \n",
    "                     phon_enc_input=phon, \n",
    "                     phon_enc_pad_mask=torch.zeros_like(phon).bool(), \n",
    "                     deterministic=True)['orth'][:, 1:]\n",
    "z_prime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.6767, -0.1219, -0.5411,  0.1170, -0.3387, -0.1288, -0.5503,\n",
       "            0.6902,  0.1972, -0.2650,  0.5467,  0.9316,  0.4024, -0.4422,\n",
       "           -0.1477,  0.7241, -0.9001, -0.2532,  0.5851,  1.1965, -0.7901,\n",
       "            0.2979, -0.0242,  0.4706,  0.8686,  0.1165,  0.4917,  0.5010,\n",
       "           -0.1539, -0.0028,  0.1609, -0.2441,  0.3435]],\n",
       "\n",
       "         [[ 0.5110,  0.4595, -0.6616,  0.0228, -0.6862,  0.1313,  0.8328,\n",
       "            0.2021,  0.2570,  0.8814,  0.1321, -0.1988, -0.1504, -0.1617,\n",
       "            0.7846, -0.2460,  0.9513, -0.4330, -0.6739,  0.0562,  0.5938,\n",
       "            0.0119, -0.3092, -0.0674,  0.9380,  0.5049,  0.0826, -0.9075,\n",
       "            0.3517,  0.6457,  0.2784, -0.3076,  0.8851]]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#assert z.item() == z_prime.item()\n",
    "\n",
    "################# Check Phonology ########################\n",
    "z = m(orth, \n",
    "      torch.zeros_like(orth).bool(), \n",
    "      orth, \n",
    "      torch.zeros_like(orth).bool(),\n",
    "      [[phon][0]], \n",
    "      torch.zeros_like(phon).bool(), \n",
    "      [[phon][0]], \n",
    "      torch.zeros_like(phon).bool()\n",
    ")['phon']; z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "z_prime = m.generate(orth, \n",
    "                     torch.zeros_like(orth).bool(), \n",
    "                     [[phon][0]], \n",
    "                     torch.zeros_like(phon).bool(), \n",
    "                     deterministic=True)['phon']\n",
    "z_prime\n",
    "\n",
    "#assert (torch.where(z[0].argmax(dim=0) == 1)[1] == z_prime[0][1]).all()\n",
    "print(len(z_prime[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "B,C,E = 2,3,4\n",
    "a = torch.rand((B,C,E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(a.transpose(1,2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4301, 0.9611, 0.7723, 0.9204, 0.1864, 0.3543, 0.0298, 0.9956,\n",
       "          0.0215, 0.8572, 0.2218, 0.4789, 0.0823, 0.7532, 0.1532, 0.0425,\n",
       "          0.4336, 0.8475, 0.8205, 0.8800, 0.2938, 0.7716, 0.4422, 0.3135,\n",
       "          0.1729, 0.0260, 0.9826, 0.9753, 0.2033, 0.6105, 0.4312, 0.0927,\n",
       "          0.9542],\n",
       "         [0.7559, 0.8657, 0.4542, 0.3938, 0.1533, 0.3608, 0.4802, 0.3396,\n",
       "          0.7139, 0.2800, 0.1930, 0.4848, 0.7758, 0.4037, 0.2637, 0.3022,\n",
       "          0.6368, 0.4707, 0.4163, 0.9229, 0.5459, 0.4463, 0.9723, 0.4306,\n",
       "          0.7044, 0.4951, 0.3131, 0.5019, 0.4948, 0.4797, 0.4198, 0.3487,\n",
       "          0.9346]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=torch.rand((1,2,33)); p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bernoulli(p[:,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "         0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bernoulli(p)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7559, 0.8657, 0.4542, 0.3938, 0.1533, 0.3608, 0.4802, 0.3396, 0.7139,\n",
       "         0.2800, 0.1930, 0.4848, 0.7758, 0.4037, 0.2637, 0.3022, 0.6368, 0.4707,\n",
       "         0.4163, 0.9229, 0.5459, 0.4463, 0.9723, 0.4306, 0.7044, 0.4951, 0.3131,\n",
       "         0.5019, 0.4948, 0.4797, 0.4198, 0.3487, 0.9346]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  8, 12, 16, 19, 20, 22, 24, 27, 32])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(p[:,1] > 0.5)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt = torch.load('models/model0_checkpoint99.pth', map_location=torch.device('cpu'))\n",
    "m = Model(len(ds.character_tokenizer), len(ds.phonology_tokenizer), d_model=chkpt['d_model'], nhead=chkpt['nhead'])\n",
    "m.load_state_dict(chkpt['model'])\n",
    "m.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word =  ['sam']\n"
     ]
    }
   ],
   "source": [
    "idx = 10040\n",
    "word = ds.words[idx:idx+1]\n",
    "print(\"word = \", word)\n",
    "batch = ds[idx:idx+1]\n",
    "#print(\"batch = \", batch)\n",
    "orth, phon = batch['orthography'].to('cpu'), batch['phonology'].to('cpu')\n",
    "orthography = orth['enc_input_ids']\n",
    "orthography_mask = orth['enc_pad_mask']\n",
    "phonology = phon['enc_input_ids']\n",
    "phonology_mask = phon['enc_pad_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = m.generate(orthography, orthography_mask, phonology, phonology_mask, deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[BOS]ci”γ[EOS][EOS][EOS][EOS][EOS][EOS][EOS][EOS][EOS][EOS][EOS][EOS]γ[EOS]γ']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.character_tokenizer.decode(generation['orth'][:,:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([31]),\n",
       " tensor([ 9, 14]),\n",
       " tensor([14, 15, 17, 26, 28, 29]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([32]),\n",
       " tensor([14, 18]),\n",
       " tensor([32]),\n",
       " tensor([32])]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation['phon'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.phonology_tokenizer.decode(generation['phon'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[BOS]', '[EOS]', '[CLS]', '[UNK]', '[PAD]', 'i', '’', '\\x80', 'o', 'f', 'โ', 'v', '“', '.', ',', 'r', \"'\", '\\x9d', '\\x9c', 'g', 'k', 'c', 'n', 'm', 'z', '-', 'y', 'e', 'h', 'j', 'p', 'x', 's', '\"', 'q', '\\x94', 'ç', '¥', 'w', '”', 'l', 'a', '!', 'u', 'b', 'd', 't', '—', 'γ']\n"
     ]
    }
   ],
   "source": [
    "print(ds.character_tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_is_protocol',\n",
       " 'character_tokenizer',\n",
       " 'dataset',\n",
       " 'phonology_tokenizer',\n",
       " 'words']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
