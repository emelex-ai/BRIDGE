{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "datasets = [0, 950]\n",
    "for epoch in datasets:  # range(0,1000,50):\n",
    "    data[epoch] = pickle.load(open(f\"pretraining_10_epoch_{epoch}.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  0\n",
      "Mean Phon Feature Accuracy =  tensor(0.8446)\n",
      "Mean Phoneme Accuracy =  tensor(0.0014)\n",
      "Dataset:  950\n",
      "Mean Phon Feature Accuracy =  tensor(0.9999)\n",
      "Mean Phoneme Accuracy =  tensor(0.9986)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for d in datasets:\n",
    "    print(\"Dataset: \", d)\n",
    "    phon_preds = data[d][\"pretraining\"][\"phon_predictions\"].clone()\n",
    "    phon_targets = data[d][\"pretraining\"][\"phon_targets\"].clone()\n",
    "    phon_features_mask = phon_targets != 2\n",
    "    masked_equalities = torch.eq(phon_preds, phon_targets) & phon_features_mask\n",
    "    print(\n",
    "        \"Mean Phon Feature Accuracy = \",\n",
    "        masked_equalities.sum() / phon_features_mask.sum(),\n",
    "    )\n",
    "    print(\n",
    "        \"Mean Phoneme Accuracy = \",\n",
    "        masked_equalities.all(dim=2).sum() / phon_features_mask.all(dim=2).sum(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3992)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(phon_preds, phon_targets).all(dim=-1).sum() / torch.prod(\n",
    "    torch.tensor(phon_preds.shape[:-1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First create two tensors\n",
    "tensor1 = torch.Tensor(\n",
    "    [[1.0, 1.0, 0.0], [0.0, 1.0, 1.0], [0.0, 0.0, 0.0], [1.0, 1.0, 0.0]]\n",
    ")\n",
    "tensor2 = torch.Tensor(\n",
    "    [[1.0, 1.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [1.0, 1.0, 0.0]]\n",
    ")\n",
    "\n",
    "# Compare along specific dimension\n",
    "result = torch.eq(tensor1, tensor2).all(dim=1)\n",
    "tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8446)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_equalities.sum() / phon_features_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_equalities.all(dim=(1, 2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phon_features_mask.all(dim=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0016)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"fry_1980\"][\"phoneme_wise_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Phon Feature Accuracy =  tensor(0.9999)\n"
     ]
    }
   ],
   "source": [
    "data = pickle.load(open(f\"pretraining_10_epoch_950.pkl\", \"rb\"))\n",
    "phon_preds = data[\"pretraining\"][\"phon_predictions\"].clone()\n",
    "phon_targets = data[\"pretraining\"][\"phon_targets\"].clone()\n",
    "# This creates a mask for the padding tokens\n",
    "phon_features_mask = phon_targets != 2\n",
    "# This finds all the equalities between the predictions and the targets and applies the mask\n",
    "masked_equalities = torch.eq(phon_preds, phon_targets) & phon_features_mask\n",
    "# This calculates the mean accuracy of the phoneme features\n",
    "print(\n",
    "    \"Mean Phon Feature Accuracy = \",\n",
    "    masked_equalities.sum() / phon_features_mask.sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "         1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"pretraining\"][\"phon_targets\"][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Word Accuracy =  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Word accuracy needs all features and all phonemes to be correct\n",
    "word_accuracy = (\n",
    "    masked_equalities.all(dim=2).all(dim=1).sum()\n",
    "    / phon_features_mask.all(dim=2).all(dim=1).sum()\n",
    ")\n",
    "print(\"Mean Word Accuracy = \", word_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Feature-Level Accuracy: 0.9998636245727539\n",
      "Overall Phoneme-Level Accuracy: 0.9986065626144409\n",
      "Overall Word-Level Accuracy: 0.9950684905052185\n",
      "\n",
      "Detailed per-word analysis:\n",
      "\n",
      "Word 0:\n",
      "Features: 66/66 correct\n",
      "Phonemes: 2/2 correct\n",
      "Word-level: Correct\n",
      "\n",
      "Word 1:\n",
      "Features: 165/165 correct\n",
      "Phonemes: 5/5 correct\n",
      "Word-level: Correct\n",
      "\n",
      "Word 2:\n",
      "Features: 132/132 correct\n",
      "Phonemes: 4/4 correct\n",
      "Word-level: Correct\n",
      "\n",
      "Word 3:\n",
      "Features: 165/165 correct\n",
      "Phonemes: 5/5 correct\n",
      "Word-level: Correct\n",
      "\n",
      "Word 4:\n",
      "Features: 132/132 correct\n",
      "Phonemes: 4/4 correct\n",
      "Word-level: Correct\n"
     ]
    }
   ],
   "source": [
    "# First clone the tensors to avoid modifying the originals\n",
    "phon_preds = data[\"pretraining\"][\"phon_predictions\"].clone()\n",
    "phon_targets = data[\"pretraining\"][\"phon_targets\"].clone()\n",
    "\n",
    "# ===== FEATURE LEVEL ACCURACY =====\n",
    "# Create mask for valid features (not padding tokens which are marked as 2)\n",
    "phon_features_mask = phon_targets != 2\n",
    "\n",
    "# Find which predictions match targets, but only count valid features\n",
    "masked_equalities = torch.eq(phon_preds, phon_targets) & phon_features_mask\n",
    "\n",
    "# Calculate overall feature accuracy across entire dataset\n",
    "feature_accuracy = masked_equalities.sum() / phon_features_mask.sum()\n",
    "print(\"\\nOverall Feature-Level Accuracy:\", feature_accuracy.item())\n",
    "\n",
    "# ===== PHONEME LEVEL ACCURACY =====\n",
    "# A phoneme is correct only if ALL its features are correct\n",
    "# We use .all(dim=2) to check across feature dimension\n",
    "phoneme_correct = masked_equalities.all(dim=2)\n",
    "\n",
    "# Identify valid phonemes (those where not all features are 2/padding)\n",
    "valid_phonemes = ~(phon_targets == 2).all(dim=2)\n",
    "\n",
    "# Calculate overall phoneme accuracy\n",
    "phoneme_accuracy = phoneme_correct[valid_phonemes].sum() / valid_phonemes.sum()\n",
    "print(\"Overall Phoneme-Level Accuracy:\", phoneme_accuracy.item())\n",
    "\n",
    "# ===== WORD LEVEL ACCURACY =====\n",
    "# A word is correct only if ALL its valid phonemes are correct\n",
    "word_correct = torch.all(phoneme_correct | ~valid_phonemes, dim=1)\n",
    "word_accuracy = word_correct.sum() / float(word_correct.size(0))\n",
    "print(\"Overall Word-Level Accuracy:\", word_accuracy.item())\n",
    "\n",
    "# ===== PER-WORD DETAILED ANALYSIS =====\n",
    "print(\"\\nDetailed per-word analysis:\")\n",
    "for i in range(min(5, len(word_correct))):  # Show first 5 words as example\n",
    "    # Count valid features for this word\n",
    "    n_valid_features = phon_features_mask[i].sum().item()\n",
    "    n_correct_features = masked_equalities[i].sum().item()\n",
    "\n",
    "    # Count valid phonemes for this word\n",
    "    n_valid_phonemes = valid_phonemes[i].sum().item()\n",
    "    n_correct_phonemes = (phoneme_correct[i] & valid_phonemes[i]).sum().item()\n",
    "\n",
    "    print(f\"\\nWord {i}:\")\n",
    "    print(f\"Features: {n_correct_features}/{n_valid_features} correct\")\n",
    "    print(f\"Phonemes: {n_correct_phonemes}/{n_valid_phonemes} correct\")\n",
    "    print(f\"Word-level: {'Correct' if word_correct[i] else 'Incorrect'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.domain.dataset import BridgeTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BridgeEncoding(orth_enc_ids=tensor([[ 0, 19, 30, 22,  1]]), orth_enc_mask=tensor([[False, False, False, False, False]]), orth_dec_ids=tensor([[ 0, 19, 30, 22]]), orth_dec_mask=tensor([[False, False, False, False]]), phon_enc_ids=[[tensor([31]), tensor([ 2,  6, 14]), tensor([14, 17, 21, 24, 26, 29]), tensor([ 4,  6, 14]), tensor([32])]], phon_enc_mask=tensor([[False, False, False, False, False]]), phon_dec_ids=[[tensor([31]), tensor([ 2,  6, 14]), tensor([14, 17, 21, 24, 26, 29]), tensor([ 4,  6, 14])]], phon_dec_mask=tensor([[False, False, False, False]]), phon_targets=tensor([[[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "          0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]]]), device=device(type='cpu'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BridgeTokenizer()\n",
    "tokenizer.encode(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
