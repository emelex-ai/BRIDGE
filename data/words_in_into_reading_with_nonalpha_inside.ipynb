{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880961e0",
   "metadata": {},
   "source": [
    "This script takes the dataset of words from Into Reading that contained nonalphabetic strings inside the word (e.g., \"band-aid\" and \"we're\") and identifies pronunciations and special frequencies for them given their special status given that they take on a new form after the nonalphabetic character is removed from inside the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7eec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2acb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw/custom_cmudict.json', 'r') as file:\n",
    "    custom_cmudict = json.load(file)\n",
    "\n",
    "cmu = nltk.corpus.cmudict.dict()\n",
    "\n",
    "special_pronunciation = pd.read_csv(\"raw/words_in_into_reading_with_nonalpha_inside_special_pronunciation.csv\")\n",
    "special_frequency = pd.read_csv(\"raw/words_in_into_reading_with_nonalpha_inside_special_frequency.csv\")\n",
    "\n",
    "ewfg = pd.read_excel(\"raw/ewfg.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb875928",
   "metadata": {},
   "source": [
    "## Special pronunciations from words in Into Reading\n",
    "Manage special pronunciations resulting from removing nonalphabetic characters inside the word (in Into Reading words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2faba0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word to add: joe's\n",
      "Word to add, with alpha only: joes\n",
      "Word in CMUdict: [['JH', 'OW1', 'Z']]\n",
      "Word alpha only in CMUdict: [['JH', 'OW1', 'Z']]\n",
      "---------------------\n",
      "Word to add: let's\n",
      "Word to add, with alpha only: lets\n",
      "Word in CMUdict: [['L', 'EH1', 'T', 'S']]\n",
      "Word alpha only in CMUdict: [['L', 'EH1', 'T', 'S']]\n",
      "---------------------\n",
      "Word to add: paul's\n",
      "Word to add, with alpha only: pauls\n",
      "Word in CMUdict: [['P', 'AO1', 'L', 'Z']]\n",
      "Word alpha only in CMUdict: [['P', 'AO1', 'L', 'Z']]\n",
      "---------------------\n",
      "Word to add: snow's\n",
      "Word to add, with alpha only: snows\n",
      "Word in CMUdict: [['S', 'N', 'OW1', 'Z']]\n",
      "Word alpha only in CMUdict: [['S', 'N', 'OW1', 'Z']]\n",
      "---------------------\n",
      "Word to add: turtle's\n",
      "Word to add, with alpha only: turtles\n",
      "Word in CMUdict: [['T', 'ER1', 'T', 'AH0', 'L', 'Z']]\n",
      "Word alpha only in CMUdict: [['T', 'ER1', 'T', 'AH0', 'L', 'Z']]\n",
      "---------------------\n",
      "Word to add: man's\n",
      "Word to add, with alpha only: mans\n",
      "Word in CMUdict: [['M', 'AE1', 'N', 'Z']]\n",
      "Word alpha only in CMUdict: [['M', 'AE1', 'N', 'Z']]\n",
      "---------------------\n",
      "Word to add: people's\n",
      "Word to add, with alpha only: peoples\n",
      "Word in CMUdict: [['P', 'IY1', 'P', 'AH0', 'L', 'Z']]\n",
      "Word alpha only in CMUdict: [['P', 'IY1', 'P', 'AH0', 'L', 'Z']]\n",
      "---------------------\n",
      "Word to add: shark's\n",
      "Word to add, with alpha only: sharks\n",
      "Word not in CMUdict\n",
      "Word alpha only in CMUdict: [['SH', 'AA1', 'R', 'K', 'S']]\n",
      "---------------------\n",
      "Word to add: song's\n",
      "Word to add, with alpha only: songs\n",
      "Word in CMUdict: [['S', 'AO1', 'NG', 'Z']]\n",
      "Word alpha only in CMUdict: [['S', 'AO1', 'NG', 'Z']]\n",
      "---------------------\n",
      "Word to add: thing's\n",
      "Word to add, with alpha only: things\n",
      "Word in CMUdict: [['TH', 'IH1', 'NG', 'Z']]\n",
      "Word alpha only in CMUdict: [['TH', 'IH1', 'NG', 'Z']]\n",
      "---------------------\n",
      "Word to add: won’t\n",
      "Word to add, with alpha only: won’t\n",
      "Word not in CMUdict\n",
      "Word alpha only not in CMUdict\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for i, row in special_pronunciation.iterrows():\n",
    "    word = row.word_with_nonalpha_inside.lower()\n",
    "    word_alpha_only = word.replace(\"'\", \"\")\n",
    "    word_alpha_only = word_alpha_only.replace(\"-\", \"\")\n",
    "    if  word_alpha_only not in custom_cmudict.keys():\n",
    "        print(\"Word to add:\", word)\n",
    "        print(\"Word to add, with alpha only:\", word_alpha_only)\n",
    "        if word in cmu.keys():\n",
    "            print(\"Word in CMUdict:\", cmu[word])\n",
    "        else:\n",
    "            print(\"Word not in CMUdict\")\n",
    "\n",
    "        if word_alpha_only in cmu.keys():\n",
    "            print(\"Word alpha only in CMUdict:\", cmu[word_alpha_only])\n",
    "        else:\n",
    "            print(\"Word alpha only not in CMUdict\")\n",
    "\n",
    "        print(\"---------------------\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8dce05",
   "metadata": {},
   "source": [
    "## Special frequencies from words in Into Reading\n",
    "Manage special pronunciations resulting from removing nonalphabetic characters inside the word (in Into Reading words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe70828",
   "metadata": {},
   "source": [
    "# For special frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292fab74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_with_nonalpha_inside_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animal's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barb's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bear's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beth's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bird's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>black-eyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blue-gray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bob's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cat's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>crab's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dad's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>elk's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>first-aid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gail's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gram's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gull's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>he'll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>house's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i'd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>i'll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>it's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>jay's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>joan's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>joe's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>let's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mark's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mom's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pal's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>paul's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>people's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pete's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>phil's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>reptile's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rose's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>seal's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>shark's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>she'll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sloth's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>snake's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>snow's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>song's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>star's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>team's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>there's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>thing's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tree's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>turtle's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>vet's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>we'll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>we're</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>whale's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>wren's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_with_nonalpha_inside_lower\n",
       "0                         animal's\n",
       "1                           barb's\n",
       "2                           bear's\n",
       "3                           beth's\n",
       "4                           bird's\n",
       "5                       black-eyed\n",
       "6                        blue-gray\n",
       "7                            bob's\n",
       "8                            cat's\n",
       "9                           crab's\n",
       "10                           dad's\n",
       "11                           elk's\n",
       "12                       first-aid\n",
       "13                          gail's\n",
       "14                          gram's\n",
       "15                          gull's\n",
       "16                           he'll\n",
       "17                         house's\n",
       "18                             i'd\n",
       "19                            i'll\n",
       "20                            it's\n",
       "21                           jay's\n",
       "22                          joan's\n",
       "23                           joe's\n",
       "24                           let's\n",
       "25                          mark's\n",
       "26                           mom's\n",
       "27                           pal's\n",
       "28                          paul's\n",
       "29                        people's\n",
       "30                          pete's\n",
       "31                          phil's\n",
       "32                       reptile's\n",
       "33                          rose's\n",
       "34                          seal's\n",
       "35                         shark's\n",
       "36                          she'll\n",
       "37                         sloth's\n",
       "38                         snake's\n",
       "39                          snow's\n",
       "40                          song's\n",
       "41                          star's\n",
       "42                          team's\n",
       "43                         there's\n",
       "44                         thing's\n",
       "45                          tree's\n",
       "46                        turtle's\n",
       "47                           vet's\n",
       "48                           we'll\n",
       "49                           we're\n",
       "50                         whale's\n",
       "51                          wren's"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "691b0a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_alpha_only in custom_cmudict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "767df41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', \"a'\", \"a'-a\", ..., 'zzzzzzz', 'zzzzzzzzzz', 'zzzzzzzzzzzzzzz'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewfg.word.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9705ab66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Both bob's and bobs are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both elk's and elks are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both he'll and hell are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both house's and houses are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both i'd and id are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both i'll and ill are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both it's and its are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both phil's and phils are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both she'll and shell are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both sloth's and sloths are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both there's and theres are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both we'll and well are in EWFG. Choose a frequency and place in custom file\n",
      "---------------------\n",
      "Both we're and were are in EWFG. Choose a frequency and place in custom file\n"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "for i, row in special_frequency.iterrows():\n",
    "\n",
    "    word = row.word_with_nonalpha_inside_lower\n",
    "    word_alpha_only = word.replace(\"'\", \"\")\n",
    "    word_alpha_only = word_alpha_only.replace(\"-\", \"\")\n",
    "    if word_alpha_only in custom_cmudict.keys():\n",
    "        if word in ewfg.word.values and word_alpha_only in ewfg.word.values:\n",
    "            tmp.append(word)\n",
    "            print(\"---------------------\")\n",
    "            print(\"Both {} and {} are in EWFG. Choose a frequency and place in custom file\".format(word, word_alpha_only))\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec851a1",
   "metadata": {},
   "source": [
    "There are 13 words that satisfy this condition in Into Reading, so we specified partifular frequencies for these words to make sure the frequency matched the word based on the pronunciation associated with its (preferred) clean form (i.e., the form reulting from removing nonalphabetic characters inside its left and right boundaries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72e025d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['W', 'IY1', 'R'], ['W', 'IH1', 'R'], ['W', 'ER1']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu[\"we're\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7570438b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['W', 'ER0']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cmudict[\"were\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
