{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "# The model currently reads the first (1-test_percent)% of the data.csv file for training and the remaining\n",
    "# (test_percent)% for testing. The current data.csv files are shuffled and words are repeated according\n",
    "# to their frequency in text. Therefore, the test set at the end may contain words that are in the\n",
    "# training set. This function takes an existing data.csv file as input and splits it into a training and\n",
    "# test set, but ensures that the words in the test set are not in the training set.\n",
    "def create_traintest_split(\n",
    "    path_to_data: str, test_percent: float = 0.05, random_seed: int = None\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Split a dataset into training and test sets, ensuring words in the test set\n",
    "    are not in the training set.\n",
    "\n",
    "    Args:\n",
    "        path_to_data (str): Path to the CSV file containing the dataset.\n",
    "        test_percent (float): Percentage of unique words to use for testing.\n",
    "        random_seed (int, optional): Seed for random number generation.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], float]: A tuple containing the new dataset and the\n",
    "        actual train-test split ratio.\n",
    "    \"\"\"\n",
    "    if random_seed:\n",
    "        random.seed(random_seed)\n",
    "\n",
    "    # Read the data efficiently and get value counts\n",
    "    word_counts = pd.read_csv(\n",
    "        path_to_data, header=None, names=[\"word\"]\n",
    "    ).word.value_counts()\n",
    "\n",
    "    # Calculate test set size and select test words\n",
    "    test_size = int(len(word_counts) * test_percent)\n",
    "    test_words = pd.Series(random.sample(list(word_counts.index), k=test_size))\n",
    "\n",
    "    # Create training set using boolean indexing and repeat\n",
    "    train_set = word_counts[~word_counts.index.isin(test_words)].repeat(\n",
    "        word_counts[~word_counts.index.isin(test_words)]\n",
    "    )\n",
    "\n",
    "    # Convert to list, shuffle, and add test words\n",
    "    train_list = train_set.index.tolist()\n",
    "    random.shuffle(train_list)\n",
    "    full_dataset = train_list + test_words.tolist()\n",
    "\n",
    "    # Calculate actual split ratio\n",
    "    train_test_split = len(train_list) / len(full_dataset)\n",
    "\n",
    "    return full_dataset, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset, train_test_split = create_traintest_split(\n",
    "    \"data/kidwords_5000000_020724.csv\", test_percent=0.05, random_seed=43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998767049204427"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4850153"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4850153"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the train_test_split ratio. This should equal the length og the new dataset\n",
    "int((1 - train_test_split) * len(new_dataset)) + int(\n",
    "    train_test_split * len(new_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['has', 'knows', 'an', 'the', 'another', 'he', 'water', 'if', 'face', 'behind']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
